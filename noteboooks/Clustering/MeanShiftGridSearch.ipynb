{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib as mpl\n",
    "os.environ['PATH'] = os.environ['PATH'] + ':/Library/TeX/texbin'\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_values = {\n",
    "    'look_distance' : [0.1],\n",
    "    'kernel_bandwidthLon' : [ 0.1, 0.15, .2, .25, .3, .35, .4, .45, .5, .55, .6, .65, .7, .75],\n",
    "    'kernel_bandwidthLat' : [ 0.02, 0.04 , 0.06, .08, .1, .12],\n",
    "    'n_iterations' : [20],\n",
    "}\n",
    "\n",
    "param_grid = ParameterGrid(param_grid_values)\n",
    "num_cpu = 20\n",
    "input_type = \"confidence_map\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_optim_folder2 = '../datasets/classification/param_optimP2'\n",
    "\n",
    "grid_image_out_dict = {}\n",
    "grid_image_out_dict_stats = {}\n",
    "\n",
    "my_len = 0\n",
    "\n",
    "for param_idx, params in enumerate(param_grid):\n",
    "    print(param_idx, params)\n",
    "\n",
    "    out_file1 = os.path.join(param_optim_folder2, f'image_outdict_dist{params[\"look_distance\"]}_Lon{params[\"kernel_bandwidthLon\"]}_lat{params[\"kernel_bandwidthLat\"]}_iter{params[\"n_iterations\"]}.json')\n",
    "    out_file2 = os.path.join(param_optim_folder2, f'image_outdictStats_dist{params[\"look_distance\"]}_Lon{params[\"kernel_bandwidthLon\"]}_lat{params[\"kernel_bandwidthLat\"]}_iter{params[\"n_iterations\"]}.json')\n",
    "    \n",
    "    with open(out_file1,'r') as f:\n",
    "        image_out_dict = json.load(f)\n",
    "    with open(out_file2,'r') as f:\n",
    "        image_out_dict_stats = json.load(f)\n",
    "\n",
    "    my_len = len(list(image_out_dict.keys()))\n",
    "\n",
    "    grid_image_out_dict[param_idx] = deepcopy(image_out_dict)\n",
    "    grid_image_out_dict_stats[param_idx] = deepcopy(image_out_dict_stats)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "from collections import Counter\n",
    "\n",
    "cur_out_stats = {\n",
    "            # General info\n",
    "            'num_DB_groups':0,\n",
    "            'num_MS_groups':0,\n",
    "\n",
    "            'matches':0,\n",
    "\n",
    "            # MS with DB matching info\n",
    "            'unmatched_db':0,\n",
    "            'multiDB_singleMS': 0,\n",
    "            'db_too_far':0,\n",
    "\n",
    "\n",
    "            'unmatched_ms':0,\n",
    "            'bad_ms':0,\n",
    "            'ms_too_far':0,\n",
    "\n",
    "            \"ious\":0,\n",
    "            \"distances\":0\n",
    "\n",
    "    }\n",
    "\n",
    "stats_keys = cur_out_stats.keys()\n",
    "\n",
    "should_check =  list(stats_keys) + [\n",
    "                                        'num_rejects_all',\n",
    "                                        'num_optimizable_rejects',\n",
    "                                        'rate_optimizable_rejects',\n",
    "                                    ]\n",
    "\n",
    "gridsearch_dict_per_img = { k : np.zeros((len(param_grid_values['kernel_bandwidthLon']), \n",
    "                                   len(param_grid_values['kernel_bandwidthLat']),\n",
    "                                      my_len\n",
    "                                   ))\n",
    "                    for k in should_check}\n",
    "\n",
    "should_check_global = list(stats_keys) + [\n",
    "                                            'num_rejects_all',\n",
    "                                            'num_optimizable_rejects',\n",
    "                                            'rate_optimizable_rejects',\n",
    "                                         ]\n",
    "gridsearch_dict_total = { k : np.zeros((len(param_grid_values['kernel_bandwidthLon']), \n",
    "                                   len(param_grid_values['kernel_bandwidthLat'])\n",
    "                                   ))\n",
    "                    for k in should_check_global}\n",
    "\n",
    "grid_search_reject_distribs = {}\n",
    "\n",
    "\n",
    "for param_idx, params in enumerate(param_grid):\n",
    "#     param_idx= str(param_idx)\n",
    "    image_out_dict = grid_image_out_dict[param_idx]\n",
    "    image_out_dict_stats = grid_image_out_dict_stats[param_idx]\n",
    "    \n",
    "    # General info\n",
    "    num_DB_groups_per_image = np.array([item['num_DB_groups'] for k,item in image_out_dict_stats.items()])\n",
    "    num_MS_groups_per_image = np.array([item['num_MS_groups'] for k,item in image_out_dict_stats.items()])\n",
    "\n",
    "    diff_num_groups = num_DB_groups_per_image - num_MS_groups_per_image # should be shown on histogram , closer to 0 is better\n",
    "\n",
    "\n",
    "    # matches\n",
    "    num_MSmatchesDB = np.array([ np.sum(np.array(v['matches'])>-1) for k,v in image_out_dict_stats.items()])\n",
    "    \n",
    "    num_unmatched_db = np.array([len(v['unmatched_db']) for k,v in image_out_dict_stats.items()])\n",
    "    num_multiDB_singleMS = np.array([len(v['multiDB_singleMS']) for k,v in image_out_dict_stats.items()])\n",
    "    num_db_too_far = np.array([len(v['db_too_far']) for k,v in image_out_dict_stats.items()])\n",
    "\n",
    "\n",
    "    num_unmatchedMS = np.array([len(v['unmatched_ms']) for k,v in image_out_dict_stats.items()])\n",
    "    num_badMS = np.array([len(v['bad_ms']) for k,v in image_out_dict_stats.items()])\n",
    "    num_ms_too_far = np.array([len(v['ms_too_far']) for k,v in image_out_dict_stats.items()])\n",
    "    \n",
    "  \n",
    "    num_optimizable_rejects = num_badMS + num_multiDB_singleMS \n",
    "    num_rejects_all = num_optimizable_rejects + num_db_too_far\n",
    "\n",
    "    # get indices of current params\n",
    "    kernel_bandwidthLon_idx = param_grid_values['kernel_bandwidthLon'].index(params['kernel_bandwidthLon'])\n",
    "    kernel_bandwidthLat_idx = param_grid_values['kernel_bandwidthLat'].index(params['kernel_bandwidthLat'])\n",
    "    ############################\n",
    "    # Fill per-image dictinnary \n",
    "    ############################\n",
    "\n",
    "    # number of DB groups\n",
    "    gridsearch_dict_per_img['num_DB_groups'][kernel_bandwidthLon_idx,kernel_bandwidthLat_idx] = num_DB_groups_per_image\n",
    "    # number of MS groups\n",
    "    gridsearch_dict_per_img['num_MS_groups'][kernel_bandwidthLon_idx,kernel_bandwidthLat_idx] = num_MS_groups_per_image\n",
    "\n",
    "    # number of matches\n",
    "    # print(num_MSmatchesDB.shape)\n",
    "    # print(num_MSmatchesDB)\n",
    "    gridsearch_dict_per_img['matches'][kernel_bandwidthLon_idx,kernel_bandwidthLat_idx] = num_MSmatchesDB\n",
    "    # number of unmatched DB groups\n",
    "    gridsearch_dict_per_img['unmatched_db'][kernel_bandwidthLon_idx,kernel_bandwidthLat_idx] = num_unmatched_db\n",
    "    # number of multi DB groups matched to single MS group\n",
    "    gridsearch_dict_per_img['multiDB_singleMS'][kernel_bandwidthLon_idx,kernel_bandwidthLat_idx] = num_multiDB_singleMS\n",
    "    # number of DB groups too far from MS group\n",
    "    gridsearch_dict_per_img['db_too_far'][kernel_bandwidthLon_idx,kernel_bandwidthLat_idx] = num_db_too_far\n",
    "    # number of unmatched MS groups\n",
    "    gridsearch_dict_per_img['unmatched_ms'][kernel_bandwidthLon_idx,kernel_bandwidthLat_idx] = num_unmatchedMS\n",
    "    # number of bad MS groups\n",
    "    gridsearch_dict_per_img['bad_ms'][kernel_bandwidthLon_idx,kernel_bandwidthLat_idx] = num_badMS\n",
    "    # number of MS groups too far from DB group\n",
    "    gridsearch_dict_per_img['ms_too_far'][kernel_bandwidthLon_idx,kernel_bandwidthLat_idx] = num_ms_too_far\n",
    "\n",
    "\n",
    "    gridsearch_dict_per_img['num_optimizable_rejects'][kernel_bandwidthLon_idx,kernel_bandwidthLat_idx] = num_optimizable_rejects\n",
    "    gridsearch_dict_per_img['num_rejects_all'][kernel_bandwidthLon_idx,kernel_bandwidthLat_idx] = num_rejects_all\n",
    "     \n",
    "    ############################\n",
    "    # Fill total dictionnary\n",
    "    ############################\n",
    "    # number of DB groups\n",
    "    gridsearch_dict_total['num_DB_groups'][kernel_bandwidthLon_idx,kernel_bandwidthLat_idx] = np.sum(num_DB_groups_per_image)\n",
    "    # number of MS groups\n",
    "    gridsearch_dict_total['num_MS_groups'][kernel_bandwidthLon_idx,kernel_bandwidthLat_idx] = np.sum(num_MS_groups_per_image)\n",
    "\n",
    "    # number of matches\n",
    "    gridsearch_dict_total['matches'][kernel_bandwidthLon_idx,kernel_bandwidthLat_idx] = np.sum(num_MSmatchesDB)\n",
    "    # number of unmatched DB groups\n",
    "    gridsearch_dict_total['unmatched_db'][kernel_bandwidthLon_idx,kernel_bandwidthLat_idx] = np.sum(num_unmatched_db)\n",
    "    # number of multi DB groups matched to single MS group\n",
    "    gridsearch_dict_total['multiDB_singleMS'][kernel_bandwidthLon_idx,kernel_bandwidthLat_idx] = np.sum(num_multiDB_singleMS)\n",
    "    # number of DB groups too far from MS group\n",
    "    gridsearch_dict_total['db_too_far'][kernel_bandwidthLon_idx,kernel_bandwidthLat_idx] = np.sum(num_db_too_far)\n",
    "    # number of unmatched MS groups\n",
    "    gridsearch_dict_total['unmatched_ms'][kernel_bandwidthLon_idx,kernel_bandwidthLat_idx] = np.sum(num_unmatchedMS)\n",
    "    # number of bad MS groups\n",
    "    gridsearch_dict_total['bad_ms'][kernel_bandwidthLon_idx,kernel_bandwidthLat_idx] = np.sum(num_badMS)\n",
    "    # number of MS groups too far from DB group\n",
    "    gridsearch_dict_total['ms_too_far'][kernel_bandwidthLon_idx,kernel_bandwidthLat_idx] = np.sum(num_ms_too_far)\n",
    "    \n",
    "    \n",
    "\n",
    "    gridsearch_dict_total['num_optimizable_rejects'][kernel_bandwidthLon_idx,kernel_bandwidthLat_idx] = np.sum(num_optimizable_rejects)\n",
    "    gridsearch_dict_total['num_rejects_all'][kernel_bandwidthLon_idx,kernel_bandwidthLat_idx] = np.sum(num_rejects_all)\n",
    "\n",
    "#     break\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
