{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from email.mime import base\n",
    "from tokenize import group\n",
    "from sunscc.dataset.transform.pipelines import Compose\n",
    "import collections\n",
    "from functools import partial\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import random\n",
    "from hydra.utils import call, instantiate\n",
    "from pathlib import Path\n",
    "import skimage.io as io\n",
    "import skimage\n",
    "from skimage.measure import label, regionprops\n",
    "import skimage.exposure\n",
    "from numpy.random import default_rng\n",
    "\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import traceback\n",
    "import time\n",
    "\n",
    "from albumentations.core.transforms_interface import DualTransform\n",
    "\n",
    "from astropy.io import fits\n",
    "from sunscc.dataset.utils import *\n",
    "\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "import pickle\n",
    "\n",
    "import concurrent.futures\n",
    "from itertools import repeat\n",
    "import multiprocessing\n",
    "\n",
    "from numpy.random import default_rng\n",
    "\n",
    "%matplotlib widget\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_elapsed_time(st, msg):\n",
    "        end_time = time.time()\n",
    "        print(f'Elapsed time {msg}: {end_time - st}')\n",
    "\n",
    "class ClassificationDatasetSuperclasses(Dataset):\n",
    "\n",
    "    def __init__(\n",
    "        self, root_dir, partition, dtypes, classes,\n",
    "        first_classes, second_classes, third_classes, \n",
    "        json_file, classification='SuperClass' , transforms=None) -> None:\n",
    "        super().__init__()\n",
    "        if isinstance(transforms, collections.abc.Mapping):\n",
    "            transforms = partial(call, config=transforms)\n",
    "        elif isinstance(transforms, collections.abc.Sequence):\n",
    "            transforms_init = []\n",
    "            for transform in transforms:\n",
    "                transforms_init.append(instantiate(transform))\n",
    "            transforms = Compose(transforms_init)\n",
    "\n",
    "        self.transforms = transforms\n",
    "        self.root_dir = Path(root_dir)\n",
    "\n",
    "        self.main_dtype = dtypes[0]\n",
    "        self.mask_dtype = dtypes[1]\n",
    "\n",
    "        self.json_file = self.root_dir / json_file \n",
    "        # print(self.json_file)\n",
    "        self.partition_dict = None\n",
    "\n",
    "        self.c1_mapper = {c: i for i,c in enumerate(first_classes)}\n",
    "        self.c2_mapper = {c: i for i,c in enumerate(second_classes)}\n",
    "        self.c3_mapper = {c: i for i,c in enumerate(third_classes)}\n",
    "\n",
    "\n",
    "        with open(self.json_file, 'r') as f:\n",
    "            self.partition_dict = json.load(f)[partition]\n",
    "\n",
    "        \n",
    "        assert (classification == 'Zurich') or (classification == 'McIntosh') or (classification == 'SuperClass')\n",
    "\n",
    "        self.classification = classification\n",
    "\n",
    "        self.FirstClass_mapper = {c: i for i,c in enumerate(first_classes)}\n",
    "        self.SecondClass_mapper = {c: i for i,c in enumerate(second_classes)}\n",
    "        self.ThirdClass_mapper = {c: i for i,c in enumerate(third_classes)}\n",
    "\n",
    "        # print(classes)\n",
    "        self.files = {}\n",
    "        for i, bn in enumerate(sorted(list(self.partition_dict.keys()))):\n",
    "            bn = bn.split('_')[0]\n",
    "            # print(bn)\n",
    "            cur = {}\n",
    "            image_basename = bn + '.FTS'\n",
    "            image_filename = self.root_dir / self.main_dtype / image_basename\n",
    "\n",
    "            sun_mask_filename = self.root_dir / 'sun_mask' / (bn + '.png')\n",
    "\n",
    "\n",
    "            mask_basename = bn + '.png'\n",
    "            mask_filename = self.root_dir / self.mask_dtype / mask_basename\n",
    "\n",
    "            conf_map_basename = bn + '_proba_map.npy'\n",
    "            conf_map_filename = self.root_dir / self.mask_dtype / conf_map_basename\n",
    "\n",
    "            cur[\"name\"] = bn\n",
    "            cur[self.main_dtype] = image_filename\n",
    "            cur[self.mask_dtype] = mask_filename\n",
    "            cur[self.mask_dtype+\"_conf_map\"] = conf_map_filename\n",
    "            cur[\"sun_mask\"] = sun_mask_filename\n",
    "\n",
    "            self.files[bn] = cur\n",
    "\n",
    "        # print(self.files)\n",
    "\n",
    "        self.partition_dict\n",
    "\n",
    "        # print(list(self.partition_dict.values())[0])\n",
    "\n",
    "        self.groups = {}\n",
    "        for k,v in self.partition_dict.items():\n",
    "\n",
    "            if v[self.classification][\"1\"] in classes:\n",
    "                    self.groups[k] = v\n",
    "            else:\n",
    "                # print(v[self.classification][\"1\"])\n",
    "                pass\n",
    "\n",
    "      \n",
    "\n",
    "        self.dataset_length = len(list(self.groups.keys()))\n",
    "\n",
    "\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        # raise NotImplementedError\n",
    "        # print(self.dataset_length)\n",
    "        return self.dataset_length\n",
    "        # return 10\n",
    "    \n",
    "    def __getitem__(self, index: int, do_transform=True):\n",
    "\n",
    "        # st = time.time()\n",
    "\n",
    "        sample = {} # dictionnary with 'image', 'class', 'angular_excentricity', 'centroid_lat'\n",
    "\n",
    "        # basename = self.files[index][\"name\"]\n",
    "        k = sorted(list(self.groups.keys()))[index]\n",
    "        # print(k)\n",
    "        basename = k.split('_')[0]\n",
    "\n",
    "\n",
    "        # image_out_dict = self.partition_dict[basename]\n",
    "        group_dict = self.groups[k]\n",
    "\n",
    "        # print(group_dict)\n",
    "\n",
    "        img_name = self.files[basename][self.main_dtype] # path of FITS file\n",
    "        mask_name = self.files[basename][self.mask_dtype]\n",
    "        conf_map_name = self.files[basename][self.mask_dtype+\"_conf_map\"]\n",
    "\n",
    "        # print(img_name)\n",
    "        # st =  time.time()\n",
    "        hdulst:fits.HDUList = fits.open(img_name)\n",
    "        image = hdulst[0]\n",
    "        header = image.header\n",
    "        center = np.array(image.shape)//2\n",
    "        radius = header['SOLAR_R']\n",
    "        \n",
    "        # st = time.time()\n",
    "        sample['solar_disk'] = io.imread(self.files[basename][\"sun_mask\"])\n",
    "        # print_elapsed_time(st, 'load sun mask')\n",
    "\n",
    "\n",
    "\n",
    "        # st = time.time()\n",
    "        sample['excentricity_map'] = create_excentricity_map(sample['solar_disk'], radius, value_outside=-1)\n",
    "        # print_elapsed_time(st, 'create_excentricity_map')\n",
    "\n",
    "        # st = time.time()\n",
    "        sample['mask'] = io.imread(mask_name)#.astype(float)\n",
    "        sample['confidence_map'] = np.load(conf_map_name)\n",
    "        # print_elapsed_time(st, 'load mask and conf map')\n",
    "\n",
    "        # st = time.time()\n",
    "        sample['image'] = (image.data).astype(float)\n",
    "\n",
    "        sample['members'] = np.array(group_dict['members']) if 'members' in group_dict else np.array([0])\n",
    "        sample['members_mean_px'] = np.array(group_dict['members_mean_px']) if 'members_mean_px' in group_dict else np.array([0])\n",
    "\n",
    "        sample['name'] = basename\n",
    "        sample['group_name'] = k\n",
    "\n",
    "        sample['solar_angle'] = group_dict['angle']\n",
    "        sample['deltashapeX'] = group_dict['deltashapeX']\n",
    "        sample['deltashapeY'] = group_dict['deltashapeY']\n",
    "        \n",
    "        sample['angular_excentricity'] = np.array([group_dict[\"angular_excentricity_deg\"]])\n",
    "        sample['centroid_px'] = np.array(group_dict[\"centroid_px\"])\n",
    "        # print(sample['centroid_px'])\n",
    "        sample['centroid_Lat'] = np.array([group_dict[\"centroid_Lat\"]])\n",
    "\n",
    "        # sample['class'] = np.array([self.classes_mapper[group_dict[self.classification]]])\n",
    "        sample['class1'] = group_dict[self.classification]['1']\n",
    "        sample['class2'] = group_dict[self.classification]['2']\n",
    "        sample['class3'] = group_dict[self.classification]['3']\n",
    "        # sample['class1'] = np.array([self.FirstClass_mapper[group_dict[self.classification]['1']]])\n",
    "        # sample['class2'] = np.array([self.SecondClass_mapper[group_dict[self.classification]['2']]])\n",
    "        # sample['class3'] = np.array([self.ThirdClass_mapper[group_dict[self.classification]['3']]])\n",
    "        # print_elapsed_time(st, 'remaining operations')\n",
    "\n",
    "        if sample[\"image\"].shape == (1024,1024):\n",
    "            fig,ax = plt.subplots(2, 5, figsize=(10, 4) )\n",
    "            ax[0,0].imshow(sample[\"image\"], cmap='gray', interpolation='none')\n",
    "            ax[0,1].imshow(sample[\"mask\"], cmap='gray', interpolation='none')\n",
    "            ax[0,2].imshow(sample[\"confidence_map\"], cmap='gray', interpolation='none')\n",
    "            ax[0,3].imshow(sample[\"solar_disk\"], cmap='gray', interpolation='none')\n",
    "            ax[0,4].imshow(sample[\"excentricity_map\"], cmap='gray', interpolation='none')\n",
    "            # scatter the centroid\n",
    "            ax[0,0].scatter(sample['centroid_px'][0], sample['centroid_px'][1], c='r', s=10)\n",
    "\n",
    "            # print(sample[\"image\"].shape)\n",
    "            # double the resolution to 2048x2048 of all visual data\n",
    "            sample[\"image\"] = np.repeat(np.repeat(sample[\"image\"], 2, axis=0), 2, axis=1)\n",
    "            sample[\"mask\"] = np.repeat(np.repeat(sample[\"mask\"], 2, axis=0), 2, axis=1)\n",
    "            sample[\"confidence_map\"] = np.repeat(np.repeat(sample[\"confidence_map\"], 2, axis=0), 2, axis=1)\n",
    "            sample[\"solar_disk\"] = np.repeat(np.repeat(sample[\"solar_disk\"], 2, axis=0), 2, axis=1)\n",
    "            sample[\"excentricity_map\"] = np.repeat(np.repeat(sample[\"excentricity_map\"], 2, axis=0), 2, axis=1)\n",
    "            # print(sample[\"image\"].shape)\n",
    "            \n",
    "            # # also double the delta shape values\n",
    "            sample['deltashapeX'] = sample['deltashapeX']*2\n",
    "            sample['deltashapeY'] = sample['deltashapeY']*2\n",
    "\n",
    "            # also double the centroid values\n",
    "            sample['centroid_px'] = sample['centroid_px']*2\n",
    "\n",
    "\n",
    "            ax[1,0].imshow(sample[\"image\"], cmap='gray', interpolation='none')\n",
    "            ax[1,1].imshow(sample[\"mask\"], cmap='gray', interpolation='none')\n",
    "            ax[1,2].imshow(sample[\"confidence_map\"], cmap='gray', interpolation='none')\n",
    "            ax[1,3].imshow(sample[\"solar_disk\"], cmap='gray', interpolation='none')\n",
    "            ax[1,4].imshow(sample[\"excentricity_map\"], cmap='gray', interpolation='none')\n",
    "            # scatter the centroid\n",
    "            ax[1,0].scatter(sample['centroid_px'][0], sample['centroid_px'][1], c='r', s=10)\n",
    "\n",
    "\n",
    "\n",
    "            fig.tight_layout()\n",
    "\n",
    "            # show differences\n",
    "            \n",
    "        flip_time = \"2003-03-08T00:00:00\"\n",
    "        date = whitelight_to_datetime(basename)\n",
    "        datetime_str = datetime_to_db_string(date).replace(' ', 'T')\n",
    "        # print(datetime_str)\n",
    "        should_flip = (datetime.fromisoformat(datetime_str) - datetime.fromisoformat(flip_time)) < timedelta(0)\n",
    "        sample['should_flip'] = should_flip\n",
    "\n",
    "        if should_flip:\n",
    "            sample['image'] = np.flip(sample['image'],axis=0)\n",
    "            sample['solar_disk'] = np.flip(sample['solar_disk'],axis=0)\n",
    "            sample['mask'] = np.flip(sample['mask'],axis=0)\n",
    "            sample['confidence_map'] = np.flip(sample['confidence_map'],axis=0)\n",
    "            sample['excentricity_map'] = np.flip(sample['excentricity_map'],axis=0)\n",
    "\n",
    "\n",
    "#         st = time.time()\n",
    "        if self.transforms is not None and do_transform:\n",
    "            sample = self.transforms(**sample)\n",
    "#         print_elapsed_time(st, 'transform')\n",
    "\n",
    "        # fig,ax = plt.subplots(1, 5, figsize=(10, 4) )\n",
    "        # ax[0].imshow(sample[\"image\"], cmap='gray', interpolation='none')\n",
    "        # ax[1].imshow(sample[\"mask\"], cmap='gray', interpolation='none')\n",
    "        # ax[2].imshow(sample[\"confidence_map\"], cmap='gray', interpolation='none')\n",
    "        # ax[3].imshow(sample[\"solar_disk\"], cmap='gray', interpolation='none')\n",
    "        # ax[4].imshow(sample[\"excentricity_map\"], cmap='gray', interpolation='none')\n",
    "        \n",
    "\n",
    "        return sample\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create NPY files for faster dataset loading during training and test\n",
    "\n",
    "For each dataset (sunscc_all_revised / sunscc_overlaps_only / sunscc_no_overlap):\n",
    "\n",
    "Run all the following cells to create the npy of a given split (train/val/test).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'_target_': 'sunscc.transforms.DeepsunScaleWhitelight'}, {'_target_': 'sunscc.transforms.DeepsunScaleExcentricityMap'}, {'_target_': 'sunscc.transforms.DeepsunScaleConfidenceMap'}, {'_target_': 'sunscc.transforms.DeepsunRotateAndCropAroundGroup_Focus_Move', 'standard_height': 350, 'standard_width': 350, 'focus_on_group': '${focus_on_group}', 'random_move': '${random_move}', 'random_move_percent': '${random_move_percent}'}, {'_target_': 'sunscc.transforms.DeepsunMcIntoshScaleAdditionalInfo'}]\n"
     ]
    }
   ],
   "source": [
    "root_dir = \"../../datasets/classification/2002-2019_2\"\n",
    "\n",
    "sub_dir = 'sunscc_all_revised'\n",
    "# sub_dir = 'sunscc_OverlapOnly'\n",
    "\n",
    "partition = 'train'\n",
    "# partition = 'val'\n",
    "# partition = 'test'\n",
    "\n",
    "dtypes = ['image', 'T425-T375-T325_fgbg']\n",
    "\n",
    "classes = ['A','B','C','SuperGroup','H']\n",
    "first_classes = [ 'A','B','C','SuperGroup','H']\n",
    "second_classes= [ 'x','r','sym','asym']\n",
    "third_classes= [ \"x\",\"o\",\"frag\"]\n",
    "json_file = f'{sub_dir}/dataset_revised.json'\n",
    "\n",
    "classification = 'SuperClass'\n",
    "transforms = OmegaConf.load('../../sunscc/conf/exp/Classification_Superclasses4.yaml').dataset.train_dataset.transforms\n",
    "\n",
    "transforms[3].standard_height = 350\n",
    "transforms[3].standard_width = 350\n",
    "\n",
    "print(transforms)\n",
    "\n",
    "dataset =  ClassificationDatasetSuperclasses(root_dir, partition, dtypes, classes, first_classes, second_classes, third_classes, json_file, classification, transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_samples = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "477f240dff124297ad4c6915be1dc2db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipping sample 74\n",
      "skipping sample 489\n",
      "skipping sample 488\n",
      "skipping sample 739\n",
      "skipping sample 743\n",
      "skipping sample 751\n",
      "skipping sample 822\n",
      "skipping sample 1031\n",
      "skipping sample 1038\n",
      "skipping sample 1068\n",
      "skipping sample 1141\n",
      "skipping sample 1367\n",
      "skipping sample 1583\n",
      "skipping sample 1632\n",
      "skipping sample 3205\n"
     ]
    }
   ],
   "source": [
    "def get_sample(idx, dataset):\n",
    "    tmp = dataset[idx]\n",
    "    center  = tmp['image'].shape[0]//2 , tmp['image'].shape[1]//2\n",
    "    slice_x = center[0]-( 256 //2 ), center[0]+ (256 //2 )\n",
    "    slice_y = center[1]-( 256 //2 ), center[1]+ (256 //2 )\n",
    "    center_region = tmp['confidence_map'][slice_x[0]:slice_x[1], slice_y[0]:slice_y[1]]\n",
    "    if np.sum(center_region) == 0:\n",
    "        print('skipping sample', idx)\n",
    "        return None\n",
    "    return dataset[idx]\n",
    "\n",
    "num_cpu = 15\n",
    "\n",
    "\n",
    "with concurrent.futures.ProcessPoolExecutor(max_workers=int(num_cpu)) as executor:\n",
    "    for sample in tqdm(executor.map(get_sample, range(len(dataset)) , repeat(deepcopy(dataset)))):\n",
    "    # for sample in tqdm(executor.map(get_sample, range(10) , repeat(deepcopy(dataset)))):\n",
    "        if sample is not None:\n",
    "            if sample['group_name'] not in partition_samples:\n",
    "                partition_samples[sample['group_name']] = sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "npy_file = os.path.join(root_dir, sub_dir, f'all_samples_{partition}.npy')\n",
    "\n",
    "np.save(npy_file, partition_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "vscode": {
   "interpreter": {
    "hash": "1f3e85867ab3feeb73691fcc67a502ec8f0fc265745d17c9ab3a5329e7f22e4e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
