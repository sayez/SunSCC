{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988c3040",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "####\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "from ...sunscc.nb.load import load_from_dir2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# %matplotlib ipympl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e300202",
   "metadata": {},
   "source": [
    "# Unite All predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f27e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "run_dirs = [\n",
    "Path('../../models/WL-Excentricity_noNumeric_class1_100epochs_run21'), \n",
    "Path('../../models/WL-Excentricity_noNumeric_class1_100epochs_run22'), \n",
    "Path('../../models/WL-Excentricity_noNumeric_class1_100epochs_run23'),\n",
    "Path('../../models/WL-Excentricity_noNumeric_class1_100epochs_run24'),\n",
    "Path('../../models/WL-Excentricity_noNumeric_class1_100epochs_run25'),\n",
    "Path('../../models/WL-Excentricity_noNumeric_class1_100epochs_run26'),\n",
    "Path('../../models/WL-Excentricity_noNumeric_class1_100epochs_run27'),\n",
    "Path('../../models/WL-Excentricity_noNumeric_class1_100epochs_run28'),\n",
    "Path('../../models/WL-Excentricity_noNumeric_class1_100epochs_run29'),\n",
    "Path('../../models/WL-Excentricity_noNumeric_class1_100epochs_run30'),\n",
    " \n",
    "Path('../../models/WL-Excentricity_noNumeric_class1_100epochs_run31'),\n",
    "Path('../../models/WL-Excentricity_noNumeric_class1_100epochs_run32'),\n",
    "Path('../../models/WL-Excentricity_noNumeric_class1_100epochs_run33'),\n",
    "Path('../../models/WL-Excentricity_noNumeric_class1_100epochs_run34'),\n",
    "Path('../../models/WL-Excentricity_noNumeric_class1_100epochs_run35'),\n",
    "Path('../../models/WL-Excentricity_noNumeric_class1_100epochs_run36'),\n",
    "Path('../../models/WL-Excentricity_noNumeric_class1_100epochs_run37'),\n",
    "Path('../../models/WL-Excentricity_noNumeric_class1_100epochs_run38'),\n",
    "Path('../../models/WL-Excentricity_noNumeric_class1_100epochs_run39'),\n",
    "Path('../../models/WL-Excentricity_noNumeric_class1_100epochs_run40'),\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c66d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_bins = 11\n",
    "bins = np.linspace(0, 1, n_bins, endpoint=True)\n",
    "\n",
    "angular_excentricity = pd.read_csv(run_dirs[0] / 'results' / 'angular_excentricity.csv' )\n",
    "angular_excentricity = angular_excentricity.iloc[:, ~angular_excentricity.columns.str.contains('^Unnamed')] \n",
    "\n",
    "angular_excentricity.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc6f69d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f,a = plt.subplots(nrows=1,ncols=1,figsize=(6,4),dpi=200)\n",
    "\n",
    "angular_excentricity.hist(bins=bins, ax=a, ec='black')\n",
    "a.set_title(None)\n",
    "a.set_xlabel('Angular Excentricity')\n",
    "a.set_ylabel('Count')\n",
    "a.grid(linestyle='--', linewidth=0.5, alpha=0.5)\n",
    "f.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470780b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "huge_dict = {}\n",
    "\n",
    "with open(run_dirs[0] / 'results' / 'mappers.json', 'r') as f:\n",
    "    mapper = json.load(f)\n",
    "    \n",
    "inverted_mapper = {\n",
    "                     'inv_c1':   {str(v): k  for k,v in mapper['used_c1'].items() },\n",
    "                     'inv_c2':   {str(v): k  for k,v in mapper['used_c2'].items() },\n",
    "                     'inv_c3':   {str(v): k  for k,v in mapper['used_c3'].items() },\n",
    "                    }\n",
    "print(mapper)\n",
    "print(inverted_mapper)\n",
    "\n",
    "run_ids = [int(str(run_dir)[-2:]) for run_dir in run_dirs]\n",
    "\n",
    "#code for y1\n",
    "total_y1_pred = pd.DataFrame()\n",
    "for i, run_dir in enumerate(run_dirs):\n",
    "    run_id = int(str(run_dir)[-2:])\n",
    "    yt_1 = pd.read_csv(run_dir / 'results' / 'y1.csv' )\n",
    "    yt_1 = yt_1.loc[:, ~yt_1.columns.str.contains('^Unnamed')] \n",
    "\n",
    "    if i == 0:\n",
    "        total_y1_pred[\"GT\"] = yt_1[['y1_true']]\n",
    "\n",
    "    total_y1_pred[f'run_{run_id}'] =  yt_1['y1_pred']\n",
    "\n",
    "\n",
    "#code for y2\n",
    "total_y2_pred = pd.DataFrame()\n",
    "for i, run_dir in enumerate(run_dirs):\n",
    "    run_id = int(str(run_dir)[-2:])\n",
    "    yt_2 = pd.read_csv(run_dir / 'results' / 'y2.csv' )\n",
    "    yt_2 = yt_2.loc[:, ~yt_2.columns.str.contains('^Unnamed')] \n",
    "\n",
    "    if i == 0:\n",
    "        total_y2_pred[\"GT\"] = yt_2[['y2_true']]\n",
    "\n",
    "    total_y2_pred[f'run_{run_id}'] =  yt_2['y2_pred']\n",
    "\n",
    "#code for y3\n",
    "total_y3_pred = pd.DataFrame()\n",
    "for i, run_dir in enumerate(run_dirs):\n",
    "    run_id = int(str(run_dir)[-2:])\n",
    "    yt_3 = pd.read_csv(run_dir / 'results' / 'y3.csv' )\n",
    "    yt_3 = yt_3.loc[:, ~yt_3.columns.str.contains('^Unnamed')] \n",
    "\n",
    "    if i == 0:\n",
    "        total_y3_pred[\"GT\"] = yt_3[['y3_true']]\n",
    "\n",
    "    total_y3_pred[f'run_{run_id}'] =  yt_3['y3_pred']\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71769901",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total_correct_c1_y1_pred = pd.DataFrame()\n",
    "total_correct_c2_y2_pred = pd.DataFrame()\n",
    "total_correct_c3_y3_pred = pd.DataFrame()\n",
    "\n",
    "total_ratio_c1_y1_pred = pd.DataFrame()\n",
    "total_ratio_c2_y2_pred = pd.DataFrame()\n",
    "total_ratio_c3_y3_pred = pd.DataFrame()\n",
    "\n",
    "for i, run_dir in enumerate(run_dirs):\n",
    "    run_id = int(str(run_dir)[-2:])\n",
    "    # get predictions of class 1\n",
    "    yt_1 = pd.read_csv(run_dir / 'results' / 'y1.csv' )\n",
    "    yt_1 = yt_1.loc[:, ~yt_1.columns.str.contains('^Unnamed')] \n",
    "    \n",
    "    # get predictions of class 2\n",
    "    yt_2 = pd.read_csv(run_dir / 'results' / 'y2.csv' )\n",
    "    yt_2 = yt_2.loc[:, ~yt_2.columns.str.contains('^Unnamed')]\n",
    "\n",
    "    # get predictions of class 3\n",
    "    yt_3 = pd.read_csv(run_dir / 'results' / 'y3.csv' )\n",
    "    yt_3 = yt_3.loc[:, ~yt_3.columns.str.contains('^Unnamed')]\n",
    "    \n",
    "    if i == 0:\n",
    "        total_correct_c1_y1_pred[\"GT\"] = yt_1[['y1_true']]\n",
    "        total_correct_c2_y2_pred[\"GT\"] = yt_2[['y2_true']]\n",
    "        total_correct_c3_y3_pred[\"GT\"] = yt_3[['y3_true']]\n",
    "\n",
    "\n",
    "    # compute the ratio of correct prediction class 1\n",
    "    correct_c1 = yt_1['y1_true'] == yt_1['y1_pred']\n",
    "    correct_c1_ang = angular_excentricity[correct_c1]\n",
    "    wrong_c1 = yt_1['y1_true'] != yt_1['y1_pred']\n",
    "    wrong_c1_ang = angular_excentricity[wrong_c1]\n",
    "\n",
    "    bins_c_c1 = np.histogram(correct_c1_ang.to_numpy(), bins=bins)[0]\n",
    "    bins_w_c1 = np.histogram(wrong_c1_ang.to_numpy(), bins=bins)[0]\n",
    "\n",
    "    ratio_c1 = bins_c_c1 / (bins_c_c1 + bins_w_c1)\n",
    "    total_ratio_c1_y1_pred[f'run_{run_id}'] =  ratio_c1\n",
    "\n",
    "    # compute the ratio of correct prediction class 2\n",
    "    correct_c2 = yt_2['y2_true'] == yt_2['y2_pred']\n",
    "    correct_c2_ang = angular_excentricity[correct_c2]\n",
    "    wrong_c2 = yt_2['y2_true'] != yt_2['y2_pred']\n",
    "    wrong_c2_ang = angular_excentricity[wrong_c2]\n",
    "\n",
    "    bins_c_c2 = np.histogram(correct_c2_ang.to_numpy(), bins=bins)[0]\n",
    "    bins_w_c2 = np.histogram(wrong_c2_ang.to_numpy(), bins=bins)[0]\n",
    "\n",
    "    ratio_c2 = bins_c_c2 / (bins_c_c2 + bins_w_c2)\n",
    "    total_ratio_c2_y2_pred[f'run_{run_id}'] =  ratio_c2\n",
    "\n",
    "    # compute the ratio of correct prediction class 3\n",
    "    correct_c3 = yt_3['y3_true'] == yt_3['y3_pred']\n",
    "    correct_c3_ang = angular_excentricity[correct_c3]\n",
    "    wrong_c3 = yt_3['y3_true'] != yt_3['y3_pred']\n",
    "    wrong_c3_ang = angular_excentricity[wrong_c3]\n",
    "\n",
    "    bins_c_c3 = np.histogram(correct_c3_ang.to_numpy(), bins=bins)[0]\n",
    "    bins_w_c3 = np.histogram(wrong_c3_ang.to_numpy(), bins=bins)[0]\n",
    "\n",
    "    ratio_c3 = bins_c_c3 / (bins_c_c3 + bins_w_c3)\n",
    "    total_ratio_c3_y3_pred[f'run_{run_id}'] =  ratio_c3\n",
    "\n",
    "    f,a = plt.subplots(nrows=1,ncols=2,figsize=(6*2,4),dpi=200)\n",
    "    b_x = np.array([(bins[i]+ bins[i+1])/2 for i in range(len(bins)-1)])\n",
    "    n,_,_ =a[0].hist(angular_excentricity, bins=bins, ec='black', )\n",
    "    a[0].set_xlim([-0.1,1])\n",
    "    a[0].set_yticks(np.arange(0,np.max(n)+20,10))\n",
    "    a[0].set_xticks(np.arange(0,1,.1))\n",
    "    a[1].plot(b_x, ratio_c1, label='Z character')\n",
    "    a[1].plot(b_x,ratio_c2, label='p character')\n",
    "    a[1].plot(b_x,ratio_c3, label='c character')\n",
    "    a[1].set_xlabel('Angular Excentricity')\n",
    "    a[1].set_ylabel('Correct Classification Ratio')\n",
    "    a[1].legend()\n",
    "    a[1].set_ylim([0,1])\n",
    "    a[1].set_xlim([-0.1,1])\n",
    "    a[0].grid(linestyle='--', linewidth=0.5, alpha=0.5)\n",
    "    a[1].grid(linestyle='--', linewidth=0.5, alpha=0.5)\n",
    "    a[1].set_yticks(np.arange(0,1,.1))\n",
    "    a[1].set_xticks(np.arange(0,1,.1))\n",
    "    f.show()\n",
    "\n",
    "\n",
    "print(total_ratio_c1_y1_pred.shape)\n",
    "\n",
    "total_ratio_c1_y1_pred.info()\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef69b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_ratio_c1_y1_pred.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbed86bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(8, 4))\n",
    "\n",
    "n,_,_ =ax[0].hist(angular_excentricity, bins=bins, ec='black', )\n",
    "ax[0].set_xlim([-0.1,1])\n",
    "ax[0].set_yticks(np.arange(0,np.max(n)+20,10))\n",
    "ax[0].set_xticks(np.arange(0,1,.1))\n",
    "ax[0].set_xlabel('Normalized Angular Distance')\n",
    "# ax[0].set_ylabel('Count')\n",
    "ax[0].set_ylabel('')\n",
    "ax[0].set_title('Sunspot Distribution')\n",
    "ax[0].grid(linestyle='--', linewidth=0.5, alpha=0.5)\n",
    "\n",
    "#code for Z character\n",
    "df = total_ratio_c1_y1_pred.transpose()\n",
    "col_dict = dict(zip(df.columns, b_x))\n",
    "df = df.rename(columns=col_dict)\n",
    "melted_df = pd.melt(df, var_name='Bin', value_name='Accuracy')\n",
    "bin_means = melted_df.groupby('Bin').mean().reset_index()\n",
    "g = sns.lineplot(\n",
    "                data=bin_means,\n",
    "                x=\"Bin\",\n",
    "                y='Accuracy',\n",
    "                label='Z character',\n",
    "                ax=ax[1]\n",
    "            )\n",
    "# code for p character\n",
    "df = total_ratio_c2_y2_pred.transpose()\n",
    "col_dict = dict(zip(df.columns, b_x))\n",
    "df = df.rename(columns=col_dict)\n",
    "melted_df = pd.melt(df, var_name='Bin', value_name='Accuracy')\n",
    "bin_means = melted_df.groupby('Bin').mean().reset_index()\n",
    "g = sns.lineplot(\n",
    "                data=bin_means,\n",
    "                x=\"Bin\",\n",
    "                y='Accuracy',\n",
    "                label='p character',\n",
    "                ax=ax[1]\n",
    "            )\n",
    "# code for c character\n",
    "df = total_ratio_c3_y3_pred.transpose()\n",
    "col_dict = dict(zip(df.columns, b_x))\n",
    "df = df.rename(columns=col_dict)\n",
    "melted_df = pd.melt(df, var_name='Bin', value_name='Accuracy')\n",
    "bin_means = melted_df.groupby('Bin').mean().reset_index()\n",
    "g = sns.lineplot(\n",
    "\n",
    "                data=bin_means,\n",
    "                x=\"Bin\",\n",
    "                y='Accuracy',\n",
    "                label='c character',\n",
    "                ax=ax[1]\n",
    "            )\n",
    "        \n",
    "ax[1].grid(linestyle='--', linewidth=0.5, alpha=0.5)\n",
    "ax[1].set_ylim([0,1])\n",
    "ax[1].set_xlabel('Normalized Angular Distance')\n",
    "# ax[1].set_ylabel('Correct Classification Ratio')\n",
    "ax[1].set_ylabel('')\n",
    "ax[1].set_title('Correct Classification Ratio')\n",
    "\n",
    "ax[1].legend(loc='lower left')\n",
    "        \n",
    "fig.tight_layout()\n",
    "plt.savefig(\"Hist&Accuracy.pdf\", format=\"pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259def34",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bins = 11\n",
    "bins = np.linspace(0, 90, n_bins, endpoint=True)\n",
    "\n",
    "angular_excentricity = pd.read_csv(run_dirs[0] / 'results' / 'angular_excentricity.csv' )*90\n",
    "angular_excentricity = angular_excentricity.iloc[:, ~angular_excentricity.columns.str.contains('^Unnamed')] \n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(8, 4))\n",
    "\n",
    "n,_,_ =ax[0].hist(angular_excentricity, bins=bins, ec='black', )\n",
    "ax[0].set_xlim([-10,100])\n",
    "ax[0].set_yticks(np.arange(0,np.max(n)+20,10))\n",
    "ax[0].set_xticks(np.arange(0,100,10))\n",
    "ax[0].set_xlabel('Angular Distance')\n",
    "# ax[0].set_ylabel('Count')\n",
    "ax[0].set_ylabel('')\n",
    "ax[0].set_title('Sunspot Distribution')\n",
    "ax[0].grid(linestyle='--', linewidth=0.5, alpha=0.5)\n",
    "\n",
    "#code for Z character\n",
    "df = total_ratio_c1_y1_pred.transpose()\n",
    "col_dict = dict(zip(df.columns, b_x))\n",
    "df = df.rename(columns=col_dict)\n",
    "melted_df = pd.melt(df, var_name='Bin', value_name='Accuracy')\n",
    "bin_means = melted_df.groupby('Bin').mean().reset_index()\n",
    "g = sns.lineplot(\n",
    "                data=bin_means,\n",
    "                x=\"Bin\",\n",
    "                y='Accuracy',\n",
    "                label='Z character',\n",
    "                ax=ax[1]\n",
    "            )\n",
    "# code for p character\n",
    "df = total_ratio_c2_y2_pred.transpose()\n",
    "col_dict = dict(zip(df.columns, b_x))\n",
    "df = df.rename(columns=col_dict)\n",
    "melted_df = pd.melt(df, var_name='Bin', value_name='Accuracy')\n",
    "bin_means = melted_df.groupby('Bin').mean().reset_index()\n",
    "g = sns.lineplot(\n",
    "                data=bin_means,\n",
    "                x=\"Bin\",\n",
    "                y='Accuracy',\n",
    "                label='p character',\n",
    "                ax=ax[1]\n",
    "            )\n",
    "# code for c character\n",
    "df = total_ratio_c3_y3_pred.transpose()\n",
    "col_dict = dict(zip(df.columns, b_x))\n",
    "df = df.rename(columns=col_dict)\n",
    "melted_df = pd.melt(df, var_name='Bin', value_name='Accuracy')\n",
    "bin_means = melted_df.groupby('Bin').mean().reset_index()\n",
    "g = sns.lineplot(\n",
    "\n",
    "                data=bin_means,\n",
    "                x=\"Bin\",\n",
    "                y='Accuracy',\n",
    "                label='c character',\n",
    "                ax=ax[1]\n",
    "            )\n",
    "        \n",
    "ax[1].grid(linestyle='--', linewidth=0.5, alpha=0.5)\n",
    "ax[1].set_ylim([0,1])\n",
    "ax[1].set_xlabel('Normalized Angular Distance')\n",
    "# ax[1].set_ylabel('Correct Classification Ratio')\n",
    "ax[1].set_ylabel('')\n",
    "ax[1].set_title('Correct Classification Ratio')\n",
    "\n",
    "ax[1].legend(loc='lower left')\n",
    "        \n",
    "fig.tight_layout()\n",
    "plt.savefig(\"Hist&Accuracy.pdf\", format=\"pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e646cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bins = 11\n",
    "bins = np.linspace(0, 90, n_bins, endpoint=True)\n",
    "\n",
    "angular_excentricity = pd.read_csv(run_dirs[0] / 'results' / 'angular_excentricity.csv' )*90\n",
    "angular_excentricity = angular_excentricity.iloc[:, ~angular_excentricity.columns.str.contains('^Unnamed')] \n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(8, 4))\n",
    "\n",
    "n,_,_ =ax[0].hist(angular_excentricity, bins=bins, ec='black', )\n",
    "ax[0].set_xlim([-5,95])\n",
    "ax[0].set_yticks(np.arange(0,np.max(n)+20,10))\n",
    "ax[0].set_xticks(np.arange(0,100,10))\n",
    "ax[0].set_xlabel('Angular Distance [Deg]')\n",
    "# ax[0].set_ylabel('Count')\n",
    "ax[0].set_ylabel('')\n",
    "ax[0].set_title('Sunspot Distribution')\n",
    "ax[0].grid(linestyle='--', linewidth=0.5, alpha=0.5)\n",
    "\n",
    "#code for Z character\n",
    "df = total_ratio_c1_y1_pred.transpose()\n",
    "col_dict = dict(zip(df.columns, b_x))\n",
    "df = df.rename(columns=col_dict)\n",
    "melted_df = pd.melt(df, var_name='Bin', value_name='Accuracy')\n",
    "bin_means = melted_df.groupby('Bin').mean().reset_index()\n",
    "g = sns.lineplot(\n",
    "                data=bin_means,\n",
    "                x=\"Bin\",\n",
    "                y='Accuracy',\n",
    "                label='Z character',\n",
    "                ax=ax[1]\n",
    "            )\n",
    "# code for p character\n",
    "df = total_ratio_c2_y2_pred.transpose()\n",
    "col_dict = dict(zip(df.columns, b_x))\n",
    "df = df.rename(columns=col_dict)\n",
    "melted_df = pd.melt(df, var_name='Bin', value_name='Accuracy')\n",
    "bin_means = melted_df.groupby('Bin').mean().reset_index()\n",
    "g = sns.lineplot(\n",
    "                data=bin_means,\n",
    "                x=\"Bin\",\n",
    "                y='Accuracy',\n",
    "                label='p character',\n",
    "                ax=ax[1]\n",
    "            )\n",
    "# code for c character\n",
    "df = total_ratio_c3_y3_pred.transpose()\n",
    "col_dict = dict(zip(df.columns, b_x))\n",
    "df = df.rename(columns=col_dict)\n",
    "melted_df = pd.melt(df, var_name='Bin', value_name='Accuracy')\n",
    "bin_means = melted_df.groupby('Bin').mean().reset_index()\n",
    "g = sns.lineplot(\n",
    "\n",
    "                data=bin_means,\n",
    "                x=\"Bin\",\n",
    "                y='Accuracy',\n",
    "                label='c character',\n",
    "                ax=ax[1]\n",
    "            )\n",
    "        \n",
    "ax[1].grid(linestyle='--', linewidth=0.5, alpha=0.5)\n",
    "ax[1].set_ylim([0,1])\n",
    "ax[1].set_xlim([-5,95])\n",
    "ax[1].set_xticks(range(0,90+10,10))\n",
    "ax[1].set_xlabel('Angular Distance [Deg]')\n",
    "# ax[1].set_ylabel('Correct Classification Ratio')\n",
    "ax[1].set_ylabel('')\n",
    "ax[1].set_title('Correct Classification Ratio')\n",
    "\n",
    "ax[1].legend(loc='lower left')\n",
    "        \n",
    "fig.tight_layout()\n",
    "plt.savefig(\"Hist&Accuracy.pdf\", format=\"pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b9c3bc",
   "metadata": {},
   "source": [
    "# Majority vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63715dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mapper)\n",
    "print(inverted_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff3b210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for y1\n",
    "# for each row, get the most frequent prediction withouth the GT column and put it in a new column\n",
    "total_y1_pred['pred'] = total_y1_pred.iloc[:, 1:].mode(axis=1)[0]\n",
    "total_y1_pred['pred'] = total_y1_pred['pred'].astype(int)\n",
    "total_y1_pred['GT'] = total_y1_pred['GT'].astype(int)\n",
    "\n",
    "# create new dataframe with the GT and the pred\n",
    "federated_y1_pred = total_y1_pred[['GT', 'pred']]\n",
    "\n",
    "\n",
    "############################################################################################################\n",
    "#code for y2\n",
    "# for each row, get the most frequent prediction withouth the GT column and put it in a new column\n",
    "total_y2_pred['pred'] = total_y2_pred.iloc[:, 1:].mode(axis=1)[0]\n",
    "total_y2_pred['pred'] = total_y2_pred['pred'].astype(int)\n",
    "total_y2_pred['GT'] = total_y2_pred['GT'].astype(int)\n",
    "\n",
    "# create new dataframe with the GT and the pred\n",
    "federated_y2_pred = total_y2_pred[['GT', 'pred']]\n",
    "\n",
    "############################################################################################################\n",
    "#code for y3\n",
    "# for each row, get the most frequent prediction withouth the GT column and put it in a new column\n",
    "total_y3_pred['pred'] = total_y3_pred.iloc[:, 1:].mode(axis=1)[0]\n",
    "total_y3_pred['pred'] = total_y3_pred['pred'].astype(int)\n",
    "total_y3_pred['GT'] = total_y3_pred['GT'].astype(int)\n",
    "\n",
    "# create new dataframe with the GT and the pred\n",
    "federated_y3_pred = total_y3_pred[['GT', 'pred']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d3e1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code for y1\n",
    "used_c1 = mapper[\"used_c1\"]\n",
    "if 'SuperGroup' in used_c1.keys():\n",
    "    used_c1[\"SG\"] = used_c1.pop(\"SuperGroup\")\n",
    "    used_c1[\"H\"] = used_c1.pop(\"H\")\n",
    "    \n",
    "c1_names  = list(used_c1.keys())\n",
    "y1_true = federated_y1_pred['GT'].values\n",
    "y1_pred = federated_y1_pred['pred'].values\n",
    "conf_mat1 = confusion_matrix(y1_true,y1_pred, normalize='true')\n",
    "\n",
    "\n",
    "disp1 = ConfusionMatrixDisplay(confusion_matrix=conf_mat1,\n",
    "                                display_labels=c1_names,\n",
    "                                )\n",
    "#code for y2\n",
    "used_c2 = mapper[\"used_c2\"]\n",
    "c2_names  = list(used_c2.keys())\n",
    "y2_true = federated_y2_pred['GT'].values\n",
    "y2_pred = federated_y2_pred['pred'].values\n",
    "conf_mat2 = confusion_matrix(y2_true,y2_pred, normalize='true')\n",
    "\n",
    "disp2 = ConfusionMatrixDisplay(confusion_matrix=conf_mat2,\n",
    "                                display_labels=c2_names,\n",
    ")\n",
    "\n",
    "#code for y3\n",
    "used_c3 = mapper[\"used_c3\"]\n",
    "c3_names  = list(used_c3.keys())\n",
    "y3_true = federated_y3_pred['GT'].values\n",
    "y3_pred = federated_y3_pred['pred'].values\n",
    "conf_mat3 = confusion_matrix(y3_true,y3_pred, normalize='true')\n",
    "\n",
    "disp3 = ConfusionMatrixDisplay(confusion_matrix=conf_mat3,\n",
    "                                display_labels=c3_names,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "\n",
    "fig,ax = plt.subplots(nrows=1,ncols=3,figsize=(6*2.6,5) , gridspec_kw={'width_ratios': [33,33,33]} ,dpi=200)\n",
    "\n",
    "\n",
    "disp1.plot(ax=ax[0], cmap=plt.cm.Blues, colorbar=False)\n",
    "# ax[0].imshow(conf_mat1)\n",
    "ax[0].xaxis.tick_top()\n",
    "ax[0].xaxis.set_label_position('top')\n",
    "ax[0].set_title('Z character')\n",
    "for im in ax[0].get_images():               \n",
    "    im.set_clim(vmin=0,vmax=1)\n",
    "\n",
    "\n",
    "disp2.plot(ax=ax[1], cmap=plt.cm.Blues, colorbar=False)\n",
    "ax[1].xaxis.tick_top()\n",
    "ax[1].xaxis.set_label_position('top')\n",
    "ax[1].set_title('p character')\n",
    "for im in ax[1].get_images():               \n",
    "    im.set_clim(vmin=0,vmax=1)\n",
    "\n",
    "disp3.plot(ax=ax[2], cmap=plt.cm.Blues, colorbar=False)\n",
    "ax[2].xaxis.tick_top()\n",
    "ax[2].xaxis.set_label_position('top')\n",
    "ax[2].set_title('c character')\n",
    "for im in ax[2].get_images():               \n",
    "    im.set_clim(vmin=0,vmax=1)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.show()\n",
    "\n",
    "plt.savefig(\"VoteGlobal.pdf\", format=\"pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b101d9",
   "metadata": {},
   "source": [
    "Associated F1, precision, recall  scores ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfbda53",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Code to parse sklearn classification_report\n",
    "Original: https://gist.github.com/julienr/6b9b9a03bd8224db7b4f\n",
    "Modified to work with Python 3 and classification report averages\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "import collections\n",
    "\n",
    "def parse_classification_report(clfreport):\n",
    "    \"\"\"\n",
    "    Parse a sklearn classification report into a dict keyed by class name\n",
    "    and containing a tuple (precision, recall, fscore, support) for each class\n",
    "    \"\"\"\n",
    "    lines = clfreport.split('\\n')\n",
    "    # Remove empty lines\n",
    "    lines = list(filter(lambda l: not len(l.strip()) == 0, lines))\n",
    "    lines=[s for s in lines if 'accuracy' not in s]\n",
    "    \n",
    "    # Starts with a header, then score for each class and finally an average\n",
    "    header = lines[0]\n",
    "    cls_lines = lines[1:-1]\n",
    "    avg_line = lines[-1]\n",
    "\n",
    "    assert header.split() == ['precision', 'recall', 'f1-score', 'support']\n",
    "    assert avg_line.split()[1] == 'avg'\n",
    "\n",
    "    # We cannot simply use split because class names can have spaces. So instead\n",
    "    # figure the width of the class field by looking at the indentation of the\n",
    "    # precision header\n",
    "    cls_field_width = len(header) - len(header.lstrip())\n",
    "    # Now, collect all the class names and score in a dict\n",
    "    def parse_line(l):\n",
    "        \"\"\"Parse a line of classification_report\"\"\"\n",
    "        cls_name = l[:cls_field_width].strip()\n",
    "        precision, recall, fscore, support = l[cls_field_width:].split()\n",
    "        precision = float(precision)\n",
    "        recall = float(recall)\n",
    "        fscore = float(fscore)\n",
    "        support = int(support)\n",
    "        return (cls_name, precision, recall, fscore, support)\n",
    "\n",
    "    data = collections.OrderedDict()\n",
    "    for l in cls_lines:\n",
    "        ret = parse_line(l)\n",
    "        cls_name = ret[0]\n",
    "        scores = ret[1:]\n",
    "        data[cls_name] = scores\n",
    "\n",
    "    # average\n",
    "    data['avg'] = parse_line(avg_line)[1:]\n",
    "\n",
    "    return data\n",
    "\n",
    "def report_to_latex_table(data):\n",
    "    avg_split = False\n",
    "    out = \"\"\n",
    "    out += \"\\\\begin{table}\\n\"\n",
    "    out += \"\\\\caption{Latex Table from Classification Report}\\n\"\n",
    "    out += \"\\\\label{table:classification:report}\\n\"\n",
    "    out += \"\\\\centering\\n\"\n",
    "    out += \"\\\\begin{tabular}{c | c c c r}\\n\"\n",
    "    out += \"Class & Precision & Recall & F-score & Support\\\\\\\\\\n\"\n",
    "    out += \"\\midrule\\n\"\n",
    "    for cls, scores in data.items():\n",
    "        if 'micro' in cls:\n",
    "            out += \"\\\\midrule\\n\"\n",
    "        out += cls + \" & \" + \" & \".join([str(s) for s in scores])\n",
    "        out += \"\\\\\\\\\\n\"\n",
    "    out += \"\\\\end{tabular}\\n\"\n",
    "    out += \"\\\\end{table}\"\n",
    "    return out\n",
    "\n",
    "def print_to_file(string, filename):\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e594999",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "methods = ['micro', 'weighted']\n",
    "for method in methods:\n",
    "    print(f'##########.  {method}')\n",
    "\n",
    "    z_f1 = f1_score(y1_true,y1_pred, average=method)\n",
    "    p_f1 = f1_score(y2_true,y2_pred, average=method)\n",
    "    c_f1 = f1_score(y3_true,y3_pred, average=method)\n",
    "\n",
    "    print(f'F1 score for Z: {z_f1}')\n",
    "    print(f'F1 score for p: {p_f1}')\n",
    "    print(f'F1 score for c: {c_f1}')\n",
    "    print()\n",
    "\n",
    "    z_prec = precision_score(y1_true,y1_pred, average=method)\n",
    "    p_prec = precision_score(y2_true,y2_pred, average=method)\n",
    "    c_prec = precision_score(y3_true,y3_pred, average=method)\n",
    "\n",
    "    print(f'precision score for Z: {z_prec}')\n",
    "    print(f'precision score for p: {p_prec}')\n",
    "    print(f'precision score for c: {c_prec}')\n",
    "    print()\n",
    "\n",
    "    z_recall = recall_score(y1_true,y1_pred, average=method)\n",
    "    p_recall = recall_score(y2_true,y2_pred, average=method)\n",
    "    c_recall = recall_score(y3_true,y3_pred, average=method)\n",
    "\n",
    "    print(f'recall score for Z: {z_recall}')\n",
    "    print(f'recall score for p: {p_recall}')\n",
    "    print(f'recall score for c: {c_recall}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6b0c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "\n",
    "\n",
    "y1_true = federated_y1_pred['GT'].values\n",
    "print(y1_true.shape)\n",
    "y1_pred = federated_y1_pred['pred'].values\n",
    "print(y1_true.shape)\n",
    "\n",
    "precision, recall, fscore, support = score(y1_true, y1_pred)\n",
    "\n",
    "print('precision: {}'.format(precision))\n",
    "print('recall: {}'.format(recall))\n",
    "print('fscore: {}'.format(fscore))\n",
    "print('support: {}'.format(support))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e14e81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y1_true, y1_pred))\n",
    "\n",
    "print_to_file(metrics.classification_report(y1_true, y1_pred),'./tmp.txt')\n",
    "with open('./tmp.txt','r') as f:\n",
    "    data = parse_classification_report(f.read())\n",
    "    print(report_to_latex_table(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1848fd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "y2_true = federated_y2_pred['GT'].values\n",
    "print(y1_true.shape)\n",
    "y2_pred = federated_y2_pred['pred'].values\n",
    "print(y1_true.shape)\n",
    "\n",
    "print(metrics.classification_report(y2_true, y2_pred))\n",
    "\n",
    "print_to_file(metrics.classification_report(y2_true, y2_pred),'./tmp.txt')\n",
    "with open('./tmp.txt','r') as f:\n",
    "    data = parse_classification_report(f.read())\n",
    "    print(report_to_latex_table(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f88fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "y3_true = federated_y3_pred['GT'].values\n",
    "print(y1_true.shape)\n",
    "y3_pred = federated_y3_pred['pred'].values\n",
    "print(y1_true.shape)\n",
    "\n",
    "print_to_file(metrics.classification_report(y3_true, y3_pred),'./tmp.txt')\n",
    "with open('./tmp.txt','r') as f:\n",
    "    data = parse_classification_report(f.read())\n",
    "    print(report_to_latex_table(data))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "de33cd49",
   "metadata": {},
   "source": [
    "# Aggregation\n",
    "\n",
    "We take all predictions as coming from a single model -> the 20 predictions of a single dataset sample are considered as single predictions for 20 different samples -> all predictions are concatenated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7251c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_y1_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd6c031",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_y1_gt = pd.concat([total_y1_pred['GT'].astype(int)]*len(run_dirs))\n",
    "agg_y1_pred = pd.concat([total_y1_pred[f'run_{id}'].astype(int) for id in run_ids ], axis=0)\n",
    "\n",
    "print(agg_y1_gt.shape)\n",
    "print(agg_y1_gt.head())\n",
    "print(agg_y1_pred.shape)\n",
    "print(agg_y1_pred.head())\n",
    "\n",
    "agg_y2_gt = pd.concat([total_y2_pred['GT'].astype(int)]*len(run_dirs))\n",
    "agg_y2_pred = pd.concat([total_y2_pred[f'run_{id}'].astype(int) for id in run_ids ], axis=0)\n",
    "\n",
    "print(agg_y2_gt.shape)\n",
    "print(agg_y2_pred.shape)\n",
    "\n",
    "agg_y3_gt = pd.concat([total_y3_pred['GT'].astype(int)]*len(run_dirs))\n",
    "agg_y3_pred = pd.concat([total_y3_pred[f'run_{id}'].astype(int) for id in run_ids ], axis=0)\n",
    "\n",
    "print(agg_y3_gt.shape)\n",
    "print(agg_y3_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0146ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code for y1\n",
    "used_c1 = mapper[\"used_c1\"]\n",
    "c1_names  = list(used_c1.keys())\n",
    "y1_true = agg_y1_gt.values\n",
    "y1_pred = agg_y1_pred.values\n",
    "conf_mat1 = confusion_matrix(y1_true,y1_pred, normalize='true')\n",
    "\n",
    "\n",
    "disp1 = ConfusionMatrixDisplay(confusion_matrix=conf_mat1,\n",
    "                                display_labels=c1_names,\n",
    "                                )\n",
    "#code for y2\n",
    "used_c2 = mapper[\"used_c2\"]\n",
    "c2_names  = list(used_c2.keys())\n",
    "y2_true = agg_y2_gt.values\n",
    "y2_pred = agg_y2_pred.values\n",
    "conf_mat2 = confusion_matrix(y2_true,y2_pred, normalize='true')\n",
    "\n",
    "disp2 = ConfusionMatrixDisplay(confusion_matrix=conf_mat2,\n",
    "                                display_labels=c2_names,\n",
    ")\n",
    "\n",
    "#code for y3\n",
    "used_c3 = mapper[\"used_c3\"]\n",
    "c3_names  = list(used_c3.keys())\n",
    "y3_true = agg_y3_gt.values\n",
    "y3_pred = agg_y3_pred.values\n",
    "conf_mat3 = confusion_matrix(y3_true,y3_pred, normalize='true')\n",
    "\n",
    "disp3 = ConfusionMatrixDisplay(confusion_matrix=conf_mat3,\n",
    "                                display_labels=c3_names,\n",
    ")\n",
    "\n",
    "                            \n",
    "fig,ax = plt.subplots(nrows=1,ncols=3,figsize=(6*2.6,5) , gridspec_kw={'width_ratios': [33,33,33]} ,dpi=200)\n",
    "\n",
    "disp1.plot(ax=ax[0], cmap=plt.cm.Blues, colorbar=False)\n",
    "# ax[0].imshow(conf_mat1)\n",
    "ax[0].xaxis.tick_top()\n",
    "ax[0].xaxis.set_label_position('top')\n",
    "ax[0].set_title('Z character')\n",
    "for im in ax[0].get_images():               \n",
    "    im.set_clim(vmin=0,vmax=1)\n",
    "\n",
    "\n",
    "disp2.plot(ax=ax[1], cmap=plt.cm.Blues, colorbar=False)\n",
    "ax[1].xaxis.tick_top()\n",
    "ax[1].xaxis.set_label_position('top')\n",
    "ax[1].set_title('p character')\n",
    "for im in ax[1].get_images():               \n",
    "    im.set_clim(vmin=0,vmax=1)\n",
    "\n",
    "disp3.plot(ax=ax[2], cmap=plt.cm.Blues, colorbar=False)\n",
    "ax[2].xaxis.tick_top()\n",
    "ax[2].xaxis.set_label_position('top')\n",
    "ax[2].set_title('c character')\n",
    "for im in ax[2].get_images():               \n",
    "    im.set_clim(vmin=0,vmax=1)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.show()\n",
    "plt.savefig(\"VoteAggregation.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18305cfe",
   "metadata": {},
   "source": [
    "# Erreurs V2\n",
    "Filtrer pour ne conserver que les entrées telles que le majority vote était FAUX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2d2dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for y1\n",
    "# for each row, get the most frequent prediction withouth the GT column and put it in a new column\n",
    "total_y1_pred['pred'] = total_y1_pred.iloc[:, 1:].mode(axis=1)[0]\n",
    "total_y1_pred['pred'] = total_y1_pred['pred'].astype(int)\n",
    "total_y1_pred['GT'] = total_y1_pred['GT'].astype(int)\n",
    "\n",
    "# create new dataframe with the GT and the pred\n",
    "federated_y1_pred = total_y1_pred[['GT', 'pred']]\n",
    "\n",
    "\n",
    "############################################################################################################\n",
    "#code for y2\n",
    "# for each row, get the most frequent prediction withouth the GT column and put it in a new column\n",
    "total_y2_pred['pred'] = total_y2_pred.iloc[:, 1:].mode(axis=1)[0]\n",
    "total_y2_pred['pred'] = total_y2_pred['pred'].astype(int)\n",
    "total_y2_pred['GT'] = total_y2_pred['GT'].astype(int)\n",
    "\n",
    "# create new dataframe with the GT and the pred\n",
    "federated_y2_pred = total_y2_pred[['GT', 'pred']]\n",
    "\n",
    "############################################################################################################\n",
    "#code for y3\n",
    "# for each row, get the most frequent prediction withouth the GT column and put it in a new column\n",
    "total_y3_pred['pred'] = total_y3_pred.iloc[:, 1:].mode(axis=1)[0]\n",
    "total_y3_pred['pred'] = total_y3_pred['pred'].astype(int)\n",
    "total_y3_pred['GT'] = total_y3_pred['GT'].astype(int)\n",
    "\n",
    "# create new dataframe with the GT and the pred\n",
    "federated_y3_pred = total_y3_pred[['GT', 'pred']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040b817a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(federated_y1_pred.shape)\n",
    "err_federated_y1_pred = federated_y1_pred['GT'] != federated_y1_pred['pred']\n",
    "# get the corresponding rows in total_y1_pred\n",
    "y1_fed_errors = total_y1_pred[err_federated_y1_pred]\n",
    "\n",
    "err_federated_y2_pred = federated_y2_pred['GT'] != federated_y2_pred['pred']\n",
    "# get the corresponding rows in total_y2_pred\n",
    "y2_fed_errors = total_y2_pred[err_federated_y2_pred]\n",
    "\n",
    "err_federated_y3_pred = federated_y3_pred['GT'] != federated_y3_pred['pred']\n",
    "# get the corresponding rows in total_y3_pred\n",
    "y3_fed_errors = total_y3_pred[err_federated_y3_pred]\n",
    "\n",
    "print(y1_fed_errors.shape)\n",
    "print(y2_fed_errors.shape)\n",
    "print(y3_fed_errors.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d6bf61",
   "metadata": {},
   "source": [
    "Now, aggregate Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e0c29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_fed_y1_gt = pd.concat([y1_fed_errors['GT'].astype(int)]*len(run_dirs))\n",
    "agg_fed_y1_pred = pd.concat([y1_fed_errors[f'run_{id}'].astype(int) for id in run_ids ], axis=0)\n",
    "\n",
    "agg_fed_y2_gt = pd.concat([y2_fed_errors['GT'].astype(int)]*len(run_dirs))\n",
    "agg_fed_y2_pred = pd.concat([y2_fed_errors[f'run_{id}'].astype(int) for id in run_ids ], axis=0)\n",
    "\n",
    "agg_fed_y3_gt = pd.concat([y3_fed_errors['GT'].astype(int)]*len(run_dirs))\n",
    "agg_fed_y3_pred = pd.concat([y3_fed_errors[f'run_{id}'].astype(int) for id in run_ids ], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752e411b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code for y1\n",
    "used_c1 = mapper[\"used_c1\"]\n",
    "c1_names  = list(used_c1.keys())\n",
    "y1_true = agg_fed_y1_gt.values\n",
    "y1_pred = agg_fed_y1_pred.values\n",
    "conf_mat1 = confusion_matrix(y1_true,y1_pred, normalize='true')\n",
    "\n",
    "\n",
    "disp1 = ConfusionMatrixDisplay(confusion_matrix=conf_mat1,\n",
    "                                display_labels=c1_names,\n",
    "                                )\n",
    "#code for y2\n",
    "used_c2 = mapper[\"used_c2\"]\n",
    "c2_names  = list(used_c2.keys())\n",
    "y2_true = agg_fed_y2_gt.values\n",
    "y2_pred = agg_fed_y2_pred.values\n",
    "conf_mat2 = confusion_matrix(y2_true,y2_pred, normalize='true')\n",
    "\n",
    "disp2 = ConfusionMatrixDisplay(confusion_matrix=conf_mat2,\n",
    "                                display_labels=c2_names,\n",
    ")\n",
    "\n",
    "#code for y3\n",
    "used_c3 = mapper[\"used_c3\"]\n",
    "c3_names  = list(used_c3.keys())\n",
    "y3_true = agg_fed_y3_gt.values\n",
    "y3_pred = agg_fed_y3_pred.values\n",
    "conf_mat3 = confusion_matrix(y3_true,y3_pred, normalize='true')\n",
    "\n",
    "disp3 = ConfusionMatrixDisplay(confusion_matrix=conf_mat3,\n",
    "                                display_labels=c3_names,\n",
    ")\n",
    "\n",
    "                            \n",
    "fig,ax = plt.subplots(nrows=1,ncols=3,figsize=(6*2.6,5) , gridspec_kw={'width_ratios': [33,33,33]} ,dpi=200)\n",
    "\n",
    "# fig,ax = plt.subplots(nrows=1,ncols=4,figsize=(6*2.6,5) , gridspec_kw={'width_ratios': [33,33,33, 1]} ,dpi=200)\n",
    "# norm = matplotlib.colors.Normalize(vmin=0, vmax=1)\n",
    "# cb1 = matplotlib.colorbar.ColorbarBase(ax[3], cmap=plt.cm.Blues,\n",
    "#                                 norm=norm,\n",
    "#                                 orientation='vertical')\n",
    "\n",
    "disp1.plot(ax=ax[0], cmap=plt.cm.Blues, colorbar=False)\n",
    "# ax[0].imshow(conf_mat1)\n",
    "ax[0].xaxis.tick_top()\n",
    "ax[0].xaxis.set_label_position('top')\n",
    "ax[0].set_title('Z character')\n",
    "for im in ax[0].get_images():               \n",
    "    im.set_clim(vmin=0,vmax=1)\n",
    "\n",
    "\n",
    "disp2.plot(ax=ax[1], cmap=plt.cm.Blues, colorbar=False)\n",
    "ax[1].xaxis.tick_top()\n",
    "ax[1].xaxis.set_label_position('top')\n",
    "ax[1].set_title('p character')\n",
    "for im in ax[1].get_images():               \n",
    "    im.set_clim(vmin=0,vmax=1)\n",
    "\n",
    "disp3.plot(ax=ax[2], cmap=plt.cm.Blues, colorbar=False)\n",
    "ax[2].xaxis.tick_top()\n",
    "ax[2].xaxis.set_label_position('top')\n",
    "ax[2].set_title('c character')\n",
    "for im in ax[2].get_images():               \n",
    "    im.set_clim(vmin=0,vmax=1)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.show()\n",
    "\n",
    "plt.savefig(\"VoteErrors.pdf\", format=\"pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5745bd2",
   "metadata": {},
   "source": [
    "#### Failure cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db09e13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = {\"_target_\": \"pytorch_lightning.loggers.CSVLogger\",\n",
    "            \"save_dir\": 'csv_metrics'\n",
    "}\n",
    "config, model, dm, trainer = load_from_dir2(\n",
    "                                    run_path= run_dirs[0],\n",
    "                                    load_trainer=False,\n",
    "                                    override = [\n",
    "                                        f'~callbacks.wandb',\n",
    "\n",
    "                                        #remove wandb logger info\n",
    "                                        f\"~logger.0.project\",\n",
    "                                        f\"~logger.0.name\",\n",
    "                                        f\"~logger.0.resume\",\n",
    "                                        #replace with csv_logger\n",
    "                                        f\"logger.0._target_={logger['_target_']}\",\n",
    "                                        f\"++logger.0.save_dir={logger['save_dir']}\",\n",
    "   \n",
    "                                        f\"++callbacks.ConfusionMatrix.output_dir={str(run_dir/'results')}\",\n",
    "                                    ]\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce9ac8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d438b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the test dataloader\n",
    "test_dl = dm.test_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1244960d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = config.dataset.batch_size\n",
    "bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b020d6e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "\n",
    "for batch_idx, batch in enumerate(test_dl):\n",
    "    print(batch_idx)\n",
    "    img_indexes = (batch_idx * bs) + np.array(range(batch['image'].shape[0]))\n",
    "    print(img_indexes)\n",
    "    \n",
    "    cur_gt_1 = total_y1_pred['GT'][img_indexes]\n",
    "    cur_pred_1 = total_y1_pred['pred'][img_indexes]\n",
    "    cur_runPreds_1 = total_y1_pred[[f'run_{id}' for id in run_ids]].iloc[img_indexes]\n",
    "    cur_gt_2 = total_y2_pred['GT'][img_indexes]\n",
    "    cur_pred_2 = total_y2_pred['pred'][img_indexes]\n",
    "    cur_runPreds_2 = total_y2_pred[[f'run_{id}' for id in run_ids]].iloc[img_indexes]\n",
    "    cur_gt_3 = total_y3_pred['GT'][img_indexes]\n",
    "    cur_pred_3 = total_y3_pred['pred'][img_indexes]\n",
    "    cur_runPreds_2 = total_y3_pred[[f'run_{id}' for id in run_ids]].iloc[img_indexes]\n",
    "    \n",
    "    c1,c2,c3 = batch['class1'], batch['class2'], batch['class3']\n",
    "    gt = {'class1':c1.squeeze(1),'class2':c2.squeeze(1),'class3':c3.squeeze(1)}\n",
    "\n",
    "\n",
    "    pred =  {'class1':cur_pred_1.values,'class2':cur_pred_2.values,'class3':cur_pred_3.values}\n",
    "\n",
    "#     incorrect_idx = np.where(cur_gt_1 != cur_pred_1)[0]\n",
    "    incorrect_idx = np.where(cur_gt_1 != cur_pred_1)[0]\n",
    "#     print(incorrect_idx)\n",
    "    \n",
    "    \n",
    "#     for j in enumerate(incorrect_idx):\n",
    "    for j in incorrect_idx:\n",
    "        # show the batch['image'] at indexes where the GT and pred are different\n",
    "        img = batch['image'][j]\n",
    "        img = torch.flip(img,[0,1])\n",
    "#         print(img.shape)\n",
    "#         images_to_show = batch['image'][incorrect_idx]\n",
    "\n",
    "        g_C1 = str(int(gt['class1'][j].cpu().numpy()))\n",
    "        g_C1 = inverted_mapper['inv_c1'][g_C1]\n",
    "        g_C1 = 'SG' if g_C1 == 'SuperGroup' else g_C1\n",
    "        g_C2 = str(int(gt['class2'][j].cpu().numpy()))\n",
    "        g_C2 = inverted_mapper['inv_c2'][g_C2]\n",
    "        g_C3 = str(int(gt['class3'][j].cpu().numpy()))\n",
    "        g_C3 = inverted_mapper['inv_c3'][g_C3]\n",
    "\n",
    "        pred_C1 = str(pred['class1'][j])\n",
    "        pred_C1 = inverted_mapper['inv_c1'][pred_C1] \n",
    "        pred_C1 = 'SG' if pred_C1 == 'SuperGroup' else pred_C1\n",
    "        pred_C2 = str(pred['class2'][j])\n",
    "        pred_C2 = inverted_mapper['inv_c2'][pred_C2] \n",
    "        pred_C3 = str(pred['class3'][j])\n",
    "        pred_C3 = inverted_mapper['inv_c3'][pred_C3]\n",
    "        \n",
    "        strMcIntosh = f'{g_C1}_{g_C2}_{g_C3}'\n",
    "        strMcIntosh_hat = f'{pred_C1}_{pred_C2}_{pred_C3}'\n",
    "#         print(f\"GT: {strMcIntosh}\\nPred:{strMcIntosh_hat}\")\n",
    "        \n",
    "        # title = f\"GT: {inverted_mapper['inv_c1'][str(cur_gt[incorrect_idx[j]])]}\\n Pred: {inverted_mapper['inv_c1'][str(cur_pred[incorrect_idx[j]])]}\"\n",
    "        \n",
    "        normalize = matplotlib.colors.Normalize(vmin=0, vmax=4000)\n",
    "        \n",
    "        f = plt.figure(figsize=(8,4))\n",
    "        a = f.add_subplot(121)\n",
    "        a.imshow(3500*img, cmap='gray', norm=normalize, interpolation='none')\n",
    "        a.set_title(f\"{batch['group_name'][j]}\")\n",
    "        a.set_xlabel(f\"GT: {strMcIntosh}    Pred:{strMcIntosh_hat}\")\n",
    "        a.set_xticks([])\n",
    "        a.set_yticks([])\n",
    "        \n",
    "        b = f.add_subplot(122)\n",
    "        sns.countplot(x=cur_runPreds_1.iloc[j], ax=b, order=range(0, len(used_c1)))\n",
    "        b.set_ylabel('')\n",
    "        b.set_xlabel('')\n",
    "        b.set_xticks(range(0, len(used_c1)))\n",
    "#         b.set_xticklabels(list(used_c1.keys()), rotation=90)\n",
    "        b.set_xticklabels(list(used_c1.keys()))\n",
    "        b.set_yticklabels(range(0,len(run_dirs)+1,2))\n",
    "        b.set_ylim([0, len(run_dirs)+1])\n",
    "#         b.set_title(f'Confusion Histogram for sample')\n",
    "        b.set_title(f'Votes')\n",
    "\n",
    "#         plt.axis('off')\n",
    "\n",
    "#         print(cur_gt_1)\n",
    "#         print(error_figures_per_class[inverted_mapper['inv_c1'][str(cur_gt_1[j])]])\n",
    "        cl = inverted_mapper['inv_c1'][str(cur_gt_1[(batch_idx * bs)+j])]\n",
    "        if cl == \"SuperGroup\":\n",
    "            cl=\"SG\"\n",
    "            \n",
    "        err_kind = f'{cl}to{pred_C1}'\n",
    "            \n",
    "        out_dir = os.path.join('./Federated_errors', cl, err_kind)\n",
    "        if not os.path.isdir(out_dir):\n",
    "            os.makedirs(out_dir)\n",
    "        out_file = os.path.join(out_dir, batch['group_name'][j])\n",
    "        f.tight_layout()    \n",
    "        f.savefig(out_file+\".pdf\", format=\"pdf\", bbox_inches=\"tight\") \n",
    "#         plt.close()\n",
    "\n",
    "        f2 = plt.figure(figsize=(4.5,4))\n",
    "        a = f2.add_subplot(111)\n",
    "        a.imshow(3500*img, cmap='gray', norm=normalize, interpolation='none')\n",
    "        a.set_title(f\"{batch['group_name'][j]}\")\n",
    "        a.set_xlabel(f\"GT: {strMcIntosh}    Pred:{strMcIntosh_hat}\")\n",
    "        a.set_xticks([])\n",
    "        a.set_yticks([])\n",
    "        out_dir = os.path.join('./Federated_errors_noVotes', cl, err_kind)\n",
    "        if not os.path.isdir(out_dir):\n",
    "            os.makedirs(out_dir)\n",
    "        out_file = os.path.join(out_dir, batch['group_name'][j])\n",
    "        f2.tight_layout()    \n",
    "        f2.savefig(out_file+\".pdf\", format=\"pdf\", bbox_inches=\"tight\") \n",
    "#         plt.close()\n",
    "            \n",
    "    \n",
    "#     break\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ddfe35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from skimage.io import imread\n",
    "import glob\n",
    "i\n",
    "\n",
    "error_figures_per_class = {k:[] for k in mapper[\"used_c1\"].keys()}\n",
    "print(error_figures_per_class)\n",
    "\n",
    "\n",
    "\n",
    "for k in error_figures_per_class:\n",
    "    print(\"#####################   \",k)\n",
    "    \n",
    "    err_kinds = sorted(glob.glob(os.path.join('./Federated_errors', k,'*')))\n",
    "                       \n",
    "    for kind in err_kinds:\n",
    "        print(kind)\n",
    "        errs = sorted(glob.glob(os.path.join(kind,'*.png')))\n",
    "    \n",
    "        for err in errs:\n",
    "            im = imread(err)\n",
    "            plt.figure(figsize=(8,4))\n",
    "            ax = plt.subplot(111)\n",
    "            ax.imshow(im)\n",
    "            ax.axis('off')\n",
    "            plt.show()\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7623ab8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from skimage.io import imread\n",
    "import glob\n",
    "\n",
    "error_figures_per_class = {k:[] for k in mapper[\"used_c1\"].keys()}\n",
    "print(error_figures_per_class)\n",
    "\n",
    "\n",
    "\n",
    "for k in error_figures_per_class:\n",
    "    print(\"#####################   \",k)\n",
    "    \n",
    "    err_kinds = sorted(glob.glob(os.path.join('./Federated_errors_noVotes', k,'*')))\n",
    "                       \n",
    "    for kind in err_kinds:\n",
    "        print(kind)\n",
    "        errs = sorted(glob.glob(os.path.join(kind,'*.png')))\n",
    "    \n",
    "        for err in errs:\n",
    "            im = imread(err)\n",
    "            plt.figure(figsize=(4.5,4))\n",
    "            ax = plt.subplot(111)\n",
    "            ax.imshow(im)\n",
    "            ax.axis('off')\n",
    "            plt.show()\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f325ade",
   "metadata": {},
   "source": [
    "# Correct V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d88f85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(federated_y1_pred.shape)\n",
    "corr_federated_y1_pred = federated_y1_pred['GT'] == federated_y1_pred['pred']\n",
    "# get the corresponding rows in total_y1_pred\n",
    "y1_fed_correct = total_y1_pred[corr_federated_y1_pred]\n",
    "\n",
    "corr_federated_y2_pred = federated_y2_pred['GT'] == federated_y2_pred['pred']\n",
    "# get the corresponding rows in total_y2_pred\n",
    "y2_fed_correct = total_y2_pred[corr_federated_y2_pred]\n",
    "\n",
    "corr_federated_y3_pred = federated_y3_pred['GT'] == federated_y3_pred['pred']\n",
    "# get the corresponding rows in total_y3_pred\n",
    "y3_fed_correct = total_y3_pred[corr_federated_y3_pred]\n",
    "\n",
    "print(y1_fed_correct.shape)\n",
    "print(y2_fed_correct.shape)\n",
    "print(y3_fed_correct.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9909949",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_agg_fed_y1_gt = pd.concat([y1_fed_correct['GT'].astype(int)]*len(run_dirs))\n",
    "c_agg_fed_y1_pred = pd.concat([y1_fed_correct[f'run_{id}'].astype(int) for id in run_ids ], axis=0)\n",
    "\n",
    "c_agg_fed_y2_gt = pd.concat([y2_fed_correct['GT'].astype(int)]*len(run_dirs))\n",
    "c_agg_fed_y2_pred = pd.concat([y2_fed_correct[f'run_{id}'].astype(int) for id in run_ids ], axis=0)\n",
    "\n",
    "c_agg_fed_y3_gt = pd.concat([y3_fed_correct['GT'].astype(int)]*len(run_dirs))\n",
    "c_agg_fed_y3_pred = pd.concat([y3_fed_correct[f'run_{id}'].astype(int) for id in run_ids ], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184dd8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code for y1\n",
    "used_c1 = mapper[\"used_c1\"]\n",
    "c1_names  = list(used_c1.keys())\n",
    "y1_true = c_agg_fed_y1_gt.values\n",
    "y1_pred = c_agg_fed_y1_pred.values\n",
    "conf_mat1 = confusion_matrix(y1_true,y1_pred, normalize='true')\n",
    "\n",
    "\n",
    "disp1 = ConfusionMatrixDisplay(confusion_matrix=conf_mat1,\n",
    "                                display_labels=c1_names,\n",
    "                                )\n",
    "#code for y2\n",
    "used_c2 = mapper[\"used_c2\"]\n",
    "c2_names  = list(used_c2.keys())\n",
    "y2_true = c_agg_fed_y2_gt.values\n",
    "y2_pred = c_agg_fed_y2_pred.values\n",
    "conf_mat2 = confusion_matrix(y2_true,y2_pred, normalize='true')\n",
    "\n",
    "disp2 = ConfusionMatrixDisplay(confusion_matrix=conf_mat2,\n",
    "                                display_labels=c2_names,\n",
    ")\n",
    "\n",
    "#code for y3\n",
    "used_c3 = mapper[\"used_c3\"]\n",
    "c3_names  = list(used_c3.keys())\n",
    "y3_true = c_agg_fed_y3_gt.values\n",
    "y3_pred = c_agg_fed_y3_pred.values\n",
    "conf_mat3 = confusion_matrix(y3_true,y3_pred, normalize='true')\n",
    "\n",
    "disp3 = ConfusionMatrixDisplay(confusion_matrix=conf_mat3,\n",
    "                                display_labels=c3_names,\n",
    ")\n",
    "\n",
    "                            \n",
    "                            \n",
    "fig,ax = plt.subplots(nrows=1,ncols=3,figsize=(6*2.6,5) , gridspec_kw={'width_ratios': [33,33,33]} ,dpi=200)\n",
    "\n",
    "# fig,ax = plt.subplots(nrows=1,ncols=4,figsize=(6*2.6,5) , gridspec_kw={'width_ratios': [33,33,33, 1]} ,dpi=200)\n",
    "# norm = matplotlib.colors.Normalize(vmin=0, vmax=1)\n",
    "# cb1 = matplotlib.colorbar.ColorbarBase(ax[3], cmap=plt.cm.Blues,\n",
    "#                                 norm=norm,\n",
    "#                                 orientation='vertical')\n",
    "\n",
    "disp1.plot(ax=ax[0], cmap=plt.cm.Blues, colorbar=False)\n",
    "# ax[0].imshow(conf_mat1)\n",
    "ax[0].xaxis.tick_top()\n",
    "ax[0].xaxis.set_label_position('top')\n",
    "ax[0].set_title('Z character')\n",
    "for im in ax[0].get_images():               \n",
    "    im.set_clim(vmin=0,vmax=1)\n",
    "\n",
    "\n",
    "disp2.plot(ax=ax[1], cmap=plt.cm.Blues, colorbar=False)\n",
    "ax[1].xaxis.tick_top()\n",
    "ax[1].xaxis.set_label_position('top')\n",
    "ax[1].set_title('p character')\n",
    "for im in ax[1].get_images():               \n",
    "    im.set_clim(vmin=0,vmax=1)\n",
    "\n",
    "disp3.plot(ax=ax[2], cmap=plt.cm.Blues, colorbar=False)\n",
    "ax[2].xaxis.tick_top()\n",
    "ax[2].xaxis.set_label_position('top')\n",
    "ax[2].set_title('c character')\n",
    "for im in ax[2].get_images():               \n",
    "    im.set_clim(vmin=0,vmax=1)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.show()\n",
    "\n",
    "plt.savefig(\"VoteCorrect.pdf\", format=\"pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "04aadbdc",
   "metadata": {},
   "source": [
    "# Show number of correct majority votes as a fct of the number of times the correct class was voted for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35732242",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(federated_y1_pred.shape)\n",
    "corr_federated_y1_pred = federated_y1_pred['GT'] == federated_y1_pred['pred']\n",
    "# get the corresponding rows in total_y1_pred\n",
    "y1_fed_correct = total_y1_pred[corr_federated_y1_pred]\n",
    "\n",
    "corr_federated_y2_pred = federated_y2_pred['GT'] == federated_y2_pred['pred']\n",
    "# get the corresponding rows in total_y2_pred\n",
    "y2_fed_correct = total_y2_pred[corr_federated_y2_pred]\n",
    "\n",
    "corr_federated_y3_pred = federated_y3_pred['GT'] == federated_y3_pred['pred']\n",
    "# get the corresponding rows in total_y3_pred\n",
    "y3_fed_correct = total_y3_pred[corr_federated_y3_pred]\n",
    "\n",
    "print(y1_fed_correct.shape)\n",
    "print(y2_fed_correct.shape)\n",
    "print(y3_fed_correct.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d08ae62",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_fed_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a92abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_runPreds_1 = y1_fed_correct[[f'run_{id}' for id in run_ids]]\n",
    "\n",
    "counts = cur_runPreds_1.apply(lambda x: x.value_counts(), axis=1).fillna(0)\n",
    "\n",
    "print(counts)\n",
    "# y1_fed_correct = df.apply(pd.Series.value_counts, axis=1)[range(len(used_c1))].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b55e977",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "preds = total_y1_pred[[f'run_{id}' for id in run_ids]]\n",
    "# count the number of times each value occurs in each row, if the it is not in the row, then it is 0\n",
    "preds_counts = preds.apply(lambda x: x.value_counts(), axis=1).fillna(0)\n",
    "\n",
    "# print('preds',preds_counts)\n",
    "\n",
    "# create a new dataframe with the same index as df, one column , and values are random integers between 0 and 4\n",
    "GT = total_y1_pred['GT'].copy()\n",
    "GT = pd.DataFrame(GT.values, index=preds_counts.index, columns=['GT'])\n",
    "\n",
    "# print('GT',GT)\n",
    "\n",
    "# get the rows of preds where max value is in the GT column\n",
    "correct = preds_counts.loc[preds_counts.idxmax(axis=1) == GT['GT']]\n",
    "correct_gt = GT.loc[preds_counts.idxmax(axis=1) == GT['GT']]\n",
    "# print(correct)\n",
    "\n",
    "# get the rows of preds where max value is not in the GT column\n",
    "incorrect = preds_counts.loc[preds_counts.idxmax(axis=1) != GT['GT']]\n",
    "incorrect_gt = GT.loc[preds_counts.idxmax(axis=1) != GT['GT']]\n",
    "# print('incorrect', incorrect)\n",
    "\n",
    "# # for each row in correct, get the value of the column with the max value\n",
    "correct_right_class = correct.max(axis=1).to_numpy()\n",
    "\n",
    "# for each row in incorrect, get the value of the column in the GT column\n",
    "np_incorrect = incorrect.to_numpy()\n",
    "np_GT = incorrect_gt.to_numpy()\n",
    "# print('np_incorrect', np_incorrect)\n",
    "# print('np_GT', np_GT)\n",
    "# for each row of np_incorrect, get the ith element of the row, where i value in np_GT\n",
    "incorrect_right_class = np.zeros(len(np_incorrect))\n",
    "for idx, gt in enumerate(np_GT):\n",
    "    # print('idx', idx, 'gt', gt, 'np_incorrect[idx, gt]', np_incorrect[idx, gt])\n",
    "    incorrect_right_class[idx] =  np_incorrect[idx, gt]\n",
    "# print(incorrect_right_class)\n",
    "\n",
    "\n",
    "incorrect_max = incorrect.max(axis=1).to_numpy()\n",
    "\n",
    "# create bins for the histogram, there should be n+1 bins, where n is the number columns in preds\n",
    "bins = np.arange(0, preds.shape[1]+1, 1)\n",
    "# print(bins)\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(131)\n",
    "plt.hist(correct_right_class, bins=bins)\n",
    "# plt.hist(correct_right_class[correct_right_class<20], bins=bins)\n",
    "plt.title('Correct Majority vote')\n",
    "plt.xlabel('Votes for correct class')\n",
    "plt.subplot(132)\n",
    "# plt.hist(incorrect_right_class[incorrect_right_class>0], bins=bins)\n",
    "plt.hist(incorrect_right_class, bins=bins)\n",
    "plt.title('Incorrect Majority votes')\n",
    "plt.xlabel('Votes for correct class')\n",
    "plt.subplot(133)\n",
    "plt.hist(incorrect_max, bins=bins)\n",
    "plt.title('Incorrect Majority votes')\n",
    "plt.xlabel('Votes for winning class')\n",
    "plt.show()\n",
    "\n",
    "correct_right_c ,_  = np.histogram(correct_right_class, bins=bins)\n",
    "incorrect_right_c ,_= np.histogram(incorrect_right_class, bins=bins)\n",
    "incorrect_max_c ,_ = np.histogram(incorrect_max, bins=bins)\n",
    "\n",
    "ratio = correct_right_c / (correct_right_c + incorrect_max_c )\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(bins[1:],ratio)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "1f3e85867ab3feeb73691fcc67a502ec8f0fc265745d17c9ab3a5329e7f22e4e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
