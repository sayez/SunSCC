{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have 2 datasets: \n",
    "\n",
    "1. **all_revised**: all the samples found using the clustering\n",
    "2. **overlapsOnly**: a subset of the first whose samples have bounding box overlapping the one of another sunspot group.\n",
    "\n",
    "We still have to filter out some edge cases, which is done in this notebook\n",
    "\n",
    "Edge cases:\n",
    "The sample is located close to the limb + another sunspot group appears in the crop, however their respective bbox did not overlap each other.\n",
    "\n",
    "\n",
    "The following cells must be run for all 3 splits: train val and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "limb_limit = 60 # angular distance threshold that should be filtered\n",
    "\n",
    "# split = 'train'\n",
    "split = 'val'\n",
    "# split = 'test'\n",
    "\n",
    "\n",
    "# dir with only overlap samples\n",
    "overlaps_dir = f'../../datasets/classification/2002-2019_2/rebuttal_overlap_only'\n",
    "overlap_json = f'{overlaps_dir}/dataset_overlapsOnly.json'\n",
    "overlap_npy = f'{overlaps_dir}/all_samples_{split}.npy'\n",
    "# dir with all samples\n",
    "all_dir = f'../../datasets/classification/2002-2019_2/rebuttal_all_revised'\n",
    "all_json = f'{all_dir}/dataset_revised.json'\n",
    "all_npy = f'{all_dir}/all_samples_{split}.npy'\n",
    "\n",
    "# go through all the sample in all_json and check if they are in overlap_json\n",
    "# if they are, check if they are within the limit\n",
    "# if they are, check if their mask contain another sample\n",
    "# if they do, remove them from all_json\n",
    "\n",
    "#open the two files\n",
    "with open(all_json, 'r') as f:\n",
    "    all_dict = json.load(f)\n",
    "with open(overlap_json, 'r') as f: \n",
    "    overlap_dict = json.load(f)\n",
    "\n",
    "# open the npy files\n",
    "all_samples = np.load(all_npy, allow_pickle=True).item()\n",
    "overlap_samples = np.load(overlap_npy, allow_pickle=True).item()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 774/774 [00:00<00:00, 3348.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping UPH20050122094506_0\n",
      "Skipping UPH20070505080705_0\n",
      "Skipping UPH20030319094901_0\n",
      "Skipping UPH20030317135451_0\n",
      "Skipping UPH20051201123624_0\n",
      "34\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# get the keys of the overlap dict\n",
    "overlap_keys = list(overlap_dict[split].keys())\n",
    "\n",
    "# get the keys of the all dict\n",
    "\n",
    "# get the keys of the all dict that are not in the overlap dict\n",
    "keys_to_remove = []\n",
    "to_count = 0\n",
    "\n",
    "show = False\n",
    "\n",
    "for cur_key in tqdm(all_dict[split]):\n",
    "    \n",
    "    # get the sample\n",
    "    cur_sample = all_dict[split][cur_key]\n",
    "    cur_lon = cur_sample['centroid_Lon']\n",
    "    cur_lat = cur_sample['centroid_Lat']\n",
    "\n",
    "    if cur_key not in all_samples:\n",
    "        print(f'Skipping {cur_key}')\n",
    "        continue\n",
    "\n",
    "    # get the mask\n",
    "    cur_sample_npy = all_samples[cur_key]\n",
    "\n",
    "    # print(cur_key)\n",
    "    # print(cur_sample_npy.keys())\n",
    "\n",
    "    cur_sample_conf = cur_sample_npy['confidence_map']\n",
    "    cur_sample_grp_conf = cur_sample_npy['group_confidence_map']\n",
    "    cur_sample_ang_dist = cur_sample_npy['angular_excentricity']\n",
    "\n",
    "    # print(f'{cur_sample_ang_dist}-> {cur_sample_ang_dist * 90}')\n",
    "\n",
    "    #check if sample is close to the limb\n",
    "    is_close_to_limb = False\n",
    "    if cur_sample_ang_dist * 90 > limb_limit:\n",
    "        # print(\"sample is close to limb!\")\n",
    "        is_close_to_limb = True\n",
    "\n",
    "    # check if cur_sample_conf contains other group, to do so:\n",
    "    # compute difference between cur_sample_conf and cur_sample_grp_conf\n",
    "    # if difference contains non-zero pixels, then there is another group\n",
    "    contains_other_group = False\n",
    "    diff = cur_sample_conf - cur_sample_grp_conf\n",
    "    if np.any(diff != 0):\n",
    "        # print(\"Found another group!\")\n",
    "        # print()\n",
    "        contains_other_group = True\n",
    "\n",
    "    # check if cur_sample is in overlap_dict.\n",
    "    is_in_overlap = False\n",
    "    # Attention, remove the last underscore if present.\n",
    "    # When there was some name conflict between overlapping and non-overlappig samples,\n",
    "    # the key was saved with an underscore at the end\n",
    "    tmp = cur_key[:-1] if cur_key[-1] == '_' else cur_key\n",
    "    if tmp in overlap_keys:\n",
    "        # print(\"sample is in overlap!\")\n",
    "        # print()\n",
    "        is_in_overlap = True\n",
    "\n",
    "    # # if sample is in overlap OR is close to limb and contains another group, add it to the list of keys to remove\n",
    "    # if is_in_overlap or (is_close_to_limb and contains_other_group):\n",
    "    \n",
    "    # if sample is close to limb and contains another group, add it to the list of keys to remove\n",
    "    if (is_close_to_limb and contains_other_group):\n",
    "        keys_to_remove.append(cur_key)\n",
    "\n",
    "        p1 = \"Limb\" if is_close_to_limb else \"NoLimb\"\n",
    "        p2 = \"Other\" if contains_other_group else \"NoOther\"\n",
    "        p3 = \"Overlap\" if is_in_overlap else \"NoOvervlap\"\n",
    "\n",
    "        # if (not is_in_overlap) and (is_close_to_limb and contains_other_group):\n",
    "        # if (is_close_to_limb and contains_other_group):\n",
    "        if show:\n",
    "            to_count += 1\n",
    "            # show the sample\n",
    "            fig, ax = plt.subplots(1,3, figsize=(15,5))\n",
    "            ax[0].imshow(cur_sample_conf)\n",
    "            ax[1].imshow(cur_sample_grp_conf)\n",
    "            ax[2].imshow(cur_sample_npy['image'], cmap='gray', interpolation='None')\n",
    "            fig.suptitle(f'{cur_key} : {p1} / {p2} / {p3} ')\n",
    "            fig.tight_layout()\n",
    "            fig.show()\n",
    "    \n",
    "\n",
    "\n",
    "    # break\n",
    "\n",
    "print(len(keys_to_remove))\n",
    "print(to_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 774/774 [00:00<00:00, 618831.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping UPH20050122094506_0\n",
      "Skipping UPH20070505080705_0\n",
      "Skipping UPH20030319094901_0\n",
      "Skipping UPH20030317135451_0\n",
      "Skipping UPH20051201123624_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "out_dir = f'../../datasets/classification/2002-2019_2/sunscc_all_revised_filtered'\n",
    "\n",
    "#mkdir if it does not exist\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "    \n",
    "\n",
    "# create a new dict with only the keys that are not in keys_to_remove\n",
    "new_dict = {}\n",
    "new_npy = {}\n",
    "\n",
    "for cur_key in tqdm(all_dict[split]):\n",
    "    if cur_key not in all_samples:\n",
    "        print(f'Skipping {cur_key}')\n",
    "        continue\n",
    "        \n",
    "    if cur_key not in keys_to_remove:\n",
    "        # add the sample to the new dict\n",
    "        new_dict[cur_key] = all_dict[split][cur_key]\n",
    "\n",
    "        # add the sample to the new npy\n",
    "        new_npy[cur_key] = all_samples[cur_key]\n",
    "\n",
    "\n",
    "\n",
    "# dump the new dict in a new json file\n",
    "out_json = f'{out_dir}/dataset_filtered_{split}.json'\n",
    "with open(out_json, 'w') as f:\n",
    "    json.dump(new_dict, f)\n",
    "    \n",
    "print( \"ok\" )\n",
    "\n",
    "# dump the new npy\n",
    "np.save(f'{out_dir}/all_samples_{split}', new_npy)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sunscc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
